<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深度学习的常见模型-GAN]]></title>
    <url>%2F2018%2F07%2F05%2F20180705%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B-GAN%2F</url>
    <content type="text"><![CDATA[GAN的来源 2014年Goodfellow提出Generative Adversarial Nets即生成式对抗网络，它要解决的问题是如何从训练样本中学习出新样本，训练样本是图片就生成新图片，训练样本是文章就输出新文章等等。 GANs简单的想法就是用两个模型， 一个生成模型，一个判别模型。判别模型用于判断一个给定的图片是不是真实的图片（从数据集里获取的图片），生成模型的任务是去创造一个看起来像真的图片一样的图片，有点拗口，就是说模型自己去产生一个图片，可以和你想要的图片很像。而在开始的时候这两个模型都是没有经过训练的，这两个模型一起对抗训练，生成模型产生一张图片去欺骗判别模型，然后判别模型去判断这张图片是真是假，最终在这两个模型训练的过程中，两个模型的能力越来越强，最终达到稳态。 GAN的基本组成 GAN 模型中的两位博弈方分别由生成式模型（Generative Model）和判别式模型（Discriminative Model）充当。 生成模型： G 捕捉样本数据的分布，用服从某一分布（均匀分布，高斯分布等）的噪声 z 生成一个类似真实训练数据的样本，追求效果是越像真实样本越好； 判别模型: D 是一个二分类器，估计一个样本来自于训练数据（而非生成数据）的概率，如果样本来自于真实的训练数据，D 输出大概率，否则，D 输出小概率。 可以做如下类比：生成网络 G 好比假币制造团伙，专门制造假币，判别网络 D 好比警察，专门检测使用的货币是真币还是假币，G 的目标是想方设法生成和真币一样的货币，使得 D 判别不出来，D 的目标是想方设法检测出来 G 生成的假币。 上图是GAN网络的流程图，我们用1代表真实数据，0来代表生成的假数据。对于判别器D来说，对于真实数据，它要尽可能让判别器输出值为1；而对于生成器G，根据随机噪音向量z生成假数据也输入判别器D，使得判别器输出假数据的值为1是生成器的目标，而对于这些假数据，判别器要尽可能输出0。GAN的训练过程可以看成一个博弈的过程，也可以看成2个人在玩一个极大极小值游戏，可以用如下公式表示： 其本质上是两个优化问题，把拆解就如同下面两个公式，上面是优化D的，下面是优化G的。 当优化D时，生成器确定,我们要让判别器尽可能输出高的值，所以要最大化公式(2)的值；当优化G的时候，判别器确定，我们要使判别器判断错误，尽可能使D(G(z))的值更大，所以要最小化公式(3)的值。 GAN的训练过程 下图为GAN的训练过程。生成式对抗网络主要由生成器G和判别器D组成，训练过程如下所述： 输入噪声（隐藏变量）Z 通过生成器G得到x_fake=G(z) 从真实数据集中获取一部分真实数据x_real 将两者混合x=x_fake+x_real 将数据喂入判别部分D，给定标签x_fake=0,x_real=1,这一过程就是简单的二分类 按照分类结果，回传loss 在整个过程中，D要尽可能的使D(G(z))=0,D(x_real)=1（火眼金睛，不错杀也不漏杀）。而G则要使得D(G(z))=1(即让生成的图片以假乱真) GAN的算法流程和动态求解过程如下图所示： 一开始我们确定G，最大化D，让点沿着D变大的方向移动(红色箭头)，然后我们确定D，最小化G，让点沿着G变小的方向移动(蓝色箭头)。循环上述若干步后，达到期望的鞍点(理想最优解)。 GAN的网络结构判别器(卷积) 卷积层大家应该都很熟悉了,为了方便说明，定义如下： 二维的离散卷积（N=2） 方形的特征输入（i1=i2=i） 方形的卷积核尺寸（k1=k2=k ） 每个维度相同的步长（s1=s2=s） 每个维度相同的padding (p1=p2=p) 下图(左)表示参数为 (i=5,k=3,s=2,p=1)的卷积计算过程，从计算结果可以看出输出特征的尺寸为 (o1=o2=o=3)；下图(右)表示参为 (i=6,k=3,s=2,p=1)的卷积计算过程，从计算结果可以看出输出特征的尺寸为 (o1=o2=o=3)。 从上述2个例子我们可以总结出卷积层输入特征和输出特征尺寸和卷积核参数的关系为： 生成器(反卷积) 在介绍反卷积之前，我们先来看一下卷积运算和矩阵运算之间的关系。例有如下运算(i=4,k=3,s=1,p=0)，输出为o=2。对于上述卷积运算，我们把上图所示的3x3卷积核展开成一个如下图所示的[4.16]的稀疏矩阵C，其中非0元素Wi,j表示卷积核的第i行和第j列。 我们再把4x4的输入特征展开成[16,1]的矩阵X，那么Y=CX则是一个[4,1]的输出特征矩阵，把它重新排列成2x2的输出特征就得到最终的结果，从上述分析可以看出卷积层的计算其实是可以转化成矩阵相乘的。值得注意的是，在一些深度学习网络的开源框架中，并不是通过这种转换方法来计算卷积的，因为这个转换会存在很多无用的0乘操作，caffe中具体实现卷积计算的方法可以参考impleming convolution as a matrix multiplication。 通过上述的分析，我们已经知道卷积层的前向操作可以表示为和矩阵C相乘，那么我们很容易得到卷积层的反向传播就是和C的转置相乘。 反卷积和卷积的关系如下 反卷积又称transposed（转置） convolution，我们可以看出其实卷积层的前向传播过程就是反卷积层的反向传播过程，卷积层的反向传播过程就是反卷积层的前向传播过程。因为卷积层的前向反向计算分别为乘C和CT,而反卷积层的前向反向计算分别为乘CT和(CT)T,所以他们的前向传播和反向传播刚好交换过来。同样为了说明，定义反卷积操作参数如下： 二维的离散卷积（N=2） 方形的特征输入（i1‘=i2‘=i‘） 方形的卷积核尺寸（k1‘=k2‘=k‘） 每个维度相同的步长（s1‘=s2‘=s‘） 每个维度相同的padding (p1‘=p2‘=p‘)上图表示的是参数为( i′=2,k′=3,s′=1,p′=2)的反卷积操作，其对应的卷积操作参数为 (i=4,k=3,s=1,p=0)。我们可以发现对应的卷积和非卷积操作其 (k=k′,s=s′)，但是反卷积却多了p′=2。通过对比我们可以发现卷积层中左上角的输入只对左上角的输出有贡献，所以反卷积层会出现 p′=k−p−1=2。通过示意图，我们可以发现，反卷积层的输入输出在 s=s′=1的情况下关系为： o′=i′-k′+2p′+1=i′+(k-1)-2p GAN的优点 GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播 相比其他所有模型, GAN可以产生更加清晰，真实的样本 GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域 GAN的缺点 训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的 GAN不适合处理离散形式的数据，比如文本 GAN存在训练不稳定、梯度消失、模式崩溃的问题 实例DCGAN网络网络结构 (判别器) 网络结构 (生成器) 二次元动漫人脸（共50个epoch）数据集：51223张动漫人脸，图左为原始数据集，图右为训练过程 训练过程生成效果图如下： 真实人脸（共100个epoch）数据集：CelebA 是香港中文大学的开放数据集，包含10,177个名人身份的202,599张人脸图片。（选取了25600张）,数据集如下： 训练过程生成效果图如下]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习的发展]]></title>
    <url>%2F2018%2F06%2F28%2F20180628%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%91%E5%B1%95%2F</url>
    <content type="text"><![CDATA[深度学习的发展历程 人工智能（爷爷） 机器学习（爸爸） 深度学习（儿子） 人工智能 远在古希腊时期，发明家就梦想着创造能自主思考的机器。当人类第一次构思可编程计算机时，就已经在思考计算机能否变得智能（尽管这距造出第一台计算机还有一百多年）(Lovelace, 1842)。如今，人工智能（artificialintelligence, AI）已经成为一个具有众多实际应用和活跃研究课题的领域，并且正在蓬勃发展。我们期望通过智能软件自动地处理常规劳动、理解语音或图像、帮助医学诊断和支持基础科学研究。一个人的日常生活需要关于世界的巨量知识。很多这方面的知识是主观的、直观的，因此很难通过形式化的方式表达清楚。计算机需要获取同样的知识才能表现出智能。人工智能的一个关键挑战就是如何将这些非形式化的知识传达给计算机。 机器学习 机器学习(Machine Learning)是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构并不断改善自身性能的学科。简单来说，机器学习就是通过算法，使得机器能从大量的历史数据中学习规律，从而对新的样本做智能识别或预测未来。机器学习在图像识别、语音识别、自然语言理解、天气预测、基因表达、内容推荐等很多方面的发展还存在着没有良好解决的问题。 上图是机器学习解决问题的一般流程，即将原始数据划分为训练数据和测试数据，并提取数据的特征用以训练模型，最终测试数据用来测试模型的好坏（泛化能力）。 深度学习 深度学习的概念源于人工神经网络的研究，含多隐层的多层感知机就是一种深度学习结构。深度学习通过组合低层特征形式更加抽象的高层表示属性类别或特征了，来发现数据的分布式特征表示。其动机在于建立、模拟人脑进行分析学习的神经网络，它模拟人脑的机制来解释数据，例如图像、声音和文本，深度学习是无监督学习的一种。其实，神经网络早在八九十年代就被提出过，真正使得深度学习兴起有2个方面的因素： 大数据，用于训练数据的增加； 计算机的算力大大增加，更快的CPU、通用GPU 的出现 上图是深度学习的简单结构图，主要包含三个部分：输入层（Visible layer）、隐藏层（hidden layer）和输出层（Output layer）。图中解决的是图片分类问题。输入层输入图片，即像素矩阵；对于隐藏层，第一层可以轻易地通过比较相邻像素的亮度来识别边缘。有了第一隐藏层描述的边缘，第二隐藏层可以容易地搜索可识别为角和扩展轮廓的边集合。给定第二隐藏层中关于角和轮廓的图像描述，第三隐藏层可以找到轮廓和角的特定集合来检测特定对象的整个部分；最后根据图像描述中包含的对象部分，输出层输出图片中所包含的对象类别。 深度学习常见的编程框架 观察发现，Google、Microsoft、Facebook等巨头都参与了这场深度学习框架大战，此外，还有毕业于伯克利大学的贾扬清主导开发的Caffe，蒙特利尔大学Lisa Lab团队开发的Theano，以及其他个人或商业组织贡献的框架。 另外，可以看到各大主流框架基本都支持Python，目前Python在科学计算和数据挖掘领域可以说是独领风骚。虽然有来自R、Julia等语言的竞争压力，但是Python的各种库实在是太完善了，Web开发、数据可视化、数据预处理、数据库连接、爬虫等无所不能，有一个完美的生态环境。仅在数据挖据工具链上，Python就有NumPy、SciPy、Pandas、Scikit-learn、XGBoost等组件，做数据采集和预处理都非常方便，并且之后的模型训练阶段可以和TensorFlow等基于Python的深度学习框架完美衔接。 深度学习的应用无人驾驶 深度学习在无人驾驶领域主要用于图像处理， 也就是摄像头上面。 当然也可以用于雷达的数据处理， 但是基于图像极大丰富的信息以及难以手工建模的特性， 深度学习能最大限度的发挥其优势。 在做无人车的公司中，他们都会用到三个传感器激光雷达（lidar），测距雷达（radar）和摄像头（camera），但还是会各有侧重。比如 Waymo（前谷歌无人车）以激光雷达为主，而特斯拉和中国的图森互联以摄像头为主。我们可以从特斯拉近期放出的一段无人驾驶的视频中看到特斯拉有三个摄像头传感器，左中右各一个。 从上图我们可以看出，特斯拉成功识别了道路线（红色的线）前方整个路面（右中图），这个过程就是用深度学习完成。 AlphaGo阿尔法狗 阿尔法狗（AlphaGo）是第一个击败人类职业围棋选手、第一个战胜围棋世界冠军的人工智能程序。它主要的原理就是深度学习。早在1997年，IBM的国际象棋系统深蓝，击败了世界冠军卡斯帕罗夫时，采用的算法是通过暴力搜索的方式尝试更多的下棋方法从而战胜人类，其所依赖的更多是计算机的计算资源优势。但在围棋上，深蓝的方式完全不适用。为了战胜人类围棋选手，AlphaGo需要更加智能且强大的算法。深度学习为其提供了可能。 AlphaGo主要包括三个组成部分： 蒙特卡洛搜索树（MonteCarlo tree search，MCTS） 估值网络（Value network） 策略网络（Policy notebook） AlphaGo的一个大脑——策略网络，通过深度学习在当前给定棋盘条件下，预测下一步在哪里落子。通过大量对弈棋谱获取训练数据，该网络预测人类棋手下一步落子点的准确率可达57%以上（当年数据）并可以通过自己跟自己对弈的方式提高落子水平。AlphaGo的另一个大脑——估值网络，判断在当前棋盘条件下黑子赢棋的概率。其使用的数据就是策略网络自己和自己对弈时产生的。AlphaGo使用蒙特卡罗树算法，根据策略网络和估值网络对局势的评判结果来寻找最佳落子点。 人脸识别 人脸识别的方法有很多，如face++，DeepFace，FaceNet……常规的人脸识别流程为：人脸检测—&gt;对齐—&gt;表达—&gt;分类。人脸对齐的方法包括以下几步：1.通过若干个特征点检测人脸；2.剪切；3.建立Delaunay triangulation;4.参考标准3d模型；5.将3d模型比对到图片上；6.进行仿射变形；7.最终生成正面图像。 学习深度学习所需的基础知识 高数（链式求导，偏导，微积分） 线代（各种矩阵变换、线性方程） 概率论（各种统计分布函数，贝叶斯，傅里叶变换） 信息论（熵，相对熵，最大熵模型） 数理统计和参数估计（中心极值定理，矩阵计算，最大似然估计） 机器学习算法（KNN,决策树，SVM） 编程语言（最好是python）]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>DL</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习常见模型-CNN]]></title>
    <url>%2F2018%2F06%2F21%2F20180621%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B-CNN%2F</url>
    <content type="text"><![CDATA[CNN的来源 CNN由纽约大学的Yann LeCun于1989年提出。CNN本质上是一个多层感知机，其成功的原因关键在于它所采用的局部连接和共享权值的方式。 一方面减少了的权值的数量使得网络易于优化，另一方面降低了过拟合的风险。CNN是神经网络中的一种，它的权值共享网络结构使之更类似于生物神经网络，降低了网络模型的复杂度，减少了权值的数量。 权重共享：在卷积神经网络中，卷积层的每一个卷积滤波器重复的作用于整个感受野中，对输入图像进行卷积，卷积结果构成了输入图像的特征图，提取出图像的局部特征。每一个卷积滤波器共享相同的参数，包括相同的权重矩阵和偏置项。共享权重的好处是在对图像进行特征提取时不用考虑局部特征的位置。而且权重共享提供了一种有效的方式，使要学习的卷积神经网络模型参数数量大大降低。 CNN的网络架构 卷积神经网络结构包括：卷积层，降采样层，全链接层。每一层有多个特征图，每个特征图通过一种卷积滤波器提取输入的一种特征，每个特征图有多个神经元。 卷积层（Conv） 这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”名字来源。在卷积层中，有两个关键操作：局部关联和窗口滑动。局部关联将每个神经元看作一个滤波器（filter），窗口滑动则使filter对局部数据进行计算。除了这两个操作外，还有两个名词：步长和填充值。步长（stride）为窗口一次滑动的长度，而填充值请看下图的例子。比如有一个5x5像素大小的图片，步长取2，那么则有一个像素没有办法获取到，那应该怎么办呢？ 再举一个例子，图片中输入的是一个3x4的矩阵，卷积核是一个2x2的矩阵。我们假设卷积是一次移动一个像素来操作的，那么我们首先对左上角2x2局部矩阵与卷积核进行卷积操作，即各个位置的元素相乘再相加，得到的输出矩阵S的S00的元素值为aw+bx+ey+fz。然后我们将卷积核向右平移一个像素，现在是（b,c,f,g）四个元素构成的矩阵和卷积核来卷进，得到了输出矩阵S的S01的元素，以此类推，可以得到矩阵S的S02，S10，S11，S12的元素，具体过程如下图所示。 再举一个卷积过程的例子如下：我们有下面这个绿色的5x5输入矩阵，卷积核是一个下面这个黄色的3*3矩阵。卷积的步幅是一个像素。则卷积的过程如下面的动图。卷积的结果是一个3x3的矩阵。 上面举的例子都是二维的输入，卷积的过程比较简单，那么如果输入是多维的呢？比如在前面一组卷积层+池化层的输出是3个矩阵，这3个矩阵作为输入呢，那么我们怎么去卷积呢？又比如输入的是对应RGB的彩色图像，即是三个分布对应R，G和B的矩阵呢？ 这里实际输入的是3个5x5的矩阵，在原来输入的周围加上值为0的一层padding，则输入变为如图所示的7x7的矩阵。例子里面使用了两个卷积核，我们先关注与卷积核W0。由于输入的是3个7x7的矩阵，也可以说成7x7x3的张量，所以我们对应的卷积核W0的最后一个参数也必须是3的张量，这里卷积核W0的单独子矩阵维度为3x3.那么卷积核W0实际为一个3x3x3的张量。同时和上面的例子不同的是，这里的步长为2，即每次卷积后卷积核会向后移动2个像素的位置。蓝色矩阵（输入图像） 对 粉丝矩阵（filter） 进行矩阵内积计算并将三个内积运算的结果与偏移量b像加，比如上图中，3+0+0+0=3，计算后的值，即绿色矩阵 中的一个元素。 池化层（Pooling） 池化层，又称为降采样层，使用的原因为：根据图像局部相关性的原理，对图像进行子采样可能减少计算量，同时保持图像的旋转不变性。相比卷积层的复杂，池化层简单的多，所谓的池化，个人理解就是对输入张量的各个子矩阵进行压缩。假如是2x2的池化滤波，那么就将子矩阵的每个2x2个元素变为一个元素；如果为3x3的池化滤波，就将子矩阵每3x3个元素变成一个元素，这样输入矩阵的维度就变小了。如果想将矩阵中每NxN个元素变成一个元素，则需要一个共同的池化标准。常见的池化标准有2个：MAX和Average。即取对应区域的最大值或者平均值作为池化后的元素值。下图的例子中采用的是最大池化方法，2x2的池化滤波，步长为2.首先对红色2x2区域进行池化，此区域中最大值对6，则对应池化输出的值为6。然后滤波进行移动，由于步长为2，则移动至图中绿色区域，输出最大值为8，以此类推，最终，输入的4x4的矩阵经过池化过程后，变为2x2的矩阵，得到了压缩。 全连接层（Full Connecting） 每层之间的神经元都有权重连接，通常全连接层在卷积神经网络的尾部，是同传统神经网络神经元的连接方式是一样的。全连接层和卷积层比较相似，但全连接层的输出是一个Nx1大小的向量，并通过几个全连接层对向量进行将为操作，一般采用softmax全连接。 总结 一般CNN的结构依次为 input ((conv –&gt; relu) x N–&gt;pool?) x M (fc –&gt; relu) x K fc 卷积神经网络的训练算法 与一般的机器学习算法相比，先定义Loss function,衡量和实际结果之间的差距； 找到最小化损失函数的W（权重）和b（偏置），CNN里面最常见的算法为SGD（随机梯度下降）。 卷积神经网络的优缺点优点 共享卷积核，便于处理高维数据； 不像机器学习人为提取特征，网络训练权重自动提取特征，且分类效果好。 缺点 需要大量训练样本和好的硬件支持（GPU、TPU…）; 物理含义模糊（神经网络是一种难以解释的“黑箱模型”，我们并不知道卷积层到底提取的是什么特征）。 卷积神经网络的典型结构 LeNet,最早用于手写体数字识别的卷积神经网络。 AlexNet，2012年ILSVRC比赛中获得第一名，远超过第二名，比LeNet更深，用多层小卷积层进行叠加替换大卷积层。 ZFNet，2013年ILSVRC比赛冠军 GoogleNet，2014年ILSVRC比赛冠军 VGGNet，2014年ILSVRC比赛中的模型，图像识别上略差于GoogleNet，但是在很多图像转化学习问题（比如object detection）上效果很好。 实战演练猫狗大战，即一个简单的二分类问题，训练出一个自动判别猫狗的模型 训练集（共25000张图片，猫狗各12500张）测试集（共3000张图片，猫狗各1500张） 我们通过Tensorflow这个深度学习框架来构建我们的分类网络。通过其自带的可视化工具Tensorboard我们可以看到网络的详细结构，如下左图所示。模型训练完成后，我们用测试集来测试模型的泛化能力，输入一张测试图片，导入模型，输出分类结果，示例见下右图。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CNN</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper]]></title>
    <url>%2F2018%2F06%2F08%2F20180608zookeeper%2F</url>
    <content type="text"><![CDATA[ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。zookeeper主要是写分布式程序，可总结为：一致、有头、数据数。 总述 使用zookeeper开发自己的分布式系统要注意的问题： 解决数据一致性的问题 协调各种“动物”hadoop 小象impala 黑斑羚shark 鲨鱼hive 蜂巢mahout 象夫zookeeper 动物园管理员 google三论文 GFS → HDFSBigTable → HBaseMapReduce → HadoopMRchubby → zookeeper zookeeper是什么？ NoSQL数据库CAP原理]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached安装及简单命令]]></title>
    <url>%2F2018%2F06%2F05%2F20180605memcached%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[memcached是一套分布式的高速缓存系统，由LiveJournal的Brad Fitzpatrick开发，但目前被许多网站使用。 ubuntu16.0.4下memcached的安装 linux系统安装memcached首先要安装libevent库 12sudo apt-get install libevent-devesudo apt-get install memcached 若linux系统为centos则命令为linux系统安装memcached首先要安装libevent库 12yum install libevent libevent-deveyum install memcached memcached的连接与关闭启动memcached连接 找到memcached的安装目录，自动安装memcached在/usr/local/bin/memcached路径下linux系统安装memcached首先要安装libevent库 1memcached -u root -d -m 128m -p 11211 连接memcached语法为：telnet HOST PORT本实例的memcached服务运行的主机为127.0.0.1(本机)，端口为11211linux系统安装memcached首先要安装libevent库 1telnet 127.0.0.1 11211 连接成功如下图所示： 退出命令 linux系统安装memcached首先要安装libevent库 1quit 关闭memcached 与windows直接输入memcached.exe -d stop关闭memcached不同linux需先知道memcached的进程号，再将其杀死查看进程号linux系统安装memcached首先要安装libevent库 1stats 或者 ps -ef|grep memcached 知道了memcached对应的进程号pid后，使用kill命令杀死进程即可。注意：杀死进程前必须quit退出连接linux系统安装memcached首先要安装libevent库 1kill 5070 杀死进城后再次连接memcached失败，说明memcached已经被关闭。 memcached的命令存储命令set set用于将value存储于key中，若set的key已经存在，该命令可以更新key所对应的原来的数据。语法格式如下：linux系统安装memcached首先要安装libevent库 12set key flag exptime bytes [noreply]value key：键值对中的key，用于查找缓存值flag：可以包含键值对的整型参数，客户机使用它存储关于键值对的额外信息exptime：再缓存中保存键值对的时间长度，以秒为单位，0表示永远bytes：在缓存中存储的字节数noreply：可选参数，该参数告知服务器不需要返回数据value：存储的值，始终位于第二行 add add用于将value存储在指定的key中，如果add的key已经存在，则不会更新数据，与之前的值仍然保持相同，会得到NOT_STORED的响应，但是过期的key会更新。语法格式如下：linux系统安装memcached首先要安装libevent库 12add key flags exptime bytes [noreply]value replace replace用于替换已经存在的key的value，如果可以不存在，则替换失败，并且得到NOT_STORED的响应语法格式如下：linux系统安装memcached首先要安装libevent库 12replace key flags exptime bytes [noreply]value append append用于向已经存在key的value后面追加数据语法格式如下：linux系统安装memcached首先要安装libevent库 12append key flags exptime bytes [noreply]value prepend prepend命令用于向已经存在key的value前面追加数据语法格式如下：linux系统安装memcached首先要安装libevent库 12prepend key flags exptime bytes [noreply]value cas cas用于执行一个“检查并设置”的操作，它仅在当前客户端最后一次取值后，该key对应的值没有被其他客户端修改的情况下才能够将值写入。检查是通过cas_token参数进行的，这个参数是memcached指定给已经存在的元素的一个唯一的64位值。语法格式如下：linux系统安装memcached首先要安装libevent库 12cas key flags exptime bytes unique_cas_token [noreply]value unique_cas_token是通过gets命令获取的一个唯一的64位值 查找命令get get用于获取存储在key中的value，如果key不存在，则返回空。若获取多个key的value，则使用空格将其隔开即可。语法格式如下：linux系统安装memcached首先要安装libevent库 12get keyget key1 key2 key3 gets gets用于获取CAS令牌存的value,如果key不存在，则返回空。若获取多个key的value，则使用空格将其隔开即可。语法格式如下：linux系统安装memcached首先要安装libevent库 12gets keygets key1 key2 key3 delete delete命令用于删除已经存在的key。语法格式如下：linux系统安装memcached首先要安装libevent库 1delete key [noreply] incr/decr incr和decr用于对已经存在的key的数字进行自增或自减操作。但是惭怍的数据必须是十进制的32位无符号整数，若key不存在，返回NOT_FOUND，若键的值不为数字，则返回CLIENT_ERROR，其他错误返回ERROR。语法格式如下：linux系统安装memcached首先要安装libevent库 12incr key increment_values [noreply]decr key decrement_values [noreply] increment_values为增加的数值decrement_values为减少的数值 flush_all flush_all用于清理缓存中的所有的键值对，该命令提供了一个可选参数time，用于在制定的时间后执行清理缓存操作。语法格式如下：linux系统安装memcached首先要安装libevent库 1flush_all [time] [noreply]]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis安装及简单命令]]></title>
    <url>%2F2018%2F06%2F02%2F20180602redis%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[redis是一个key-value存储系统。它支持存储的value类型相对更很多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。Redis是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Java，C/C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。 Redis：REmote DIctionary ServerRedis(远程字典服务器) 是完全开源免费的，用C语言编写，是一个高性能的（key/value）分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSQL数据库之一，也被人们称之为结构数据服务器。 Redis逐步取代memcached的原因 1.redis支持数据持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用2.redis不仅仅直迟简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储3.redis支持数据的备份，即master-slave魔术的数据备份 Redis能做什么？ 1.内存存储和持久化：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务2.取最新N个数据的操作，如：可以将最新的10条评论的ID放在redis的List集合里面3.模拟类似于HttpSession这种需要设定过期时间的功能4.发布、订阅消息系统5.定时器、计数器 与memcached区别 都是key-value存储memcached一旦服务关闭，数据会全部没有redis服务关闭重启后数据还在 安装Redis 我们的环境：VMware WorkplaceCentOS-6.5redis-4.0.9下载地址： Http://redis.io将下载好的redis-4.0.9放入虚拟机中，并解压 1tar -zxvf redis-4.9.0.tar.gz redis内包含的文件 输入命令 1make 运行运行makefile文件，要有GCC，没有则会报错。安装gcc： 1yum install gcc-c++ 安装完成之后要进行二次make，但是之前要将上一次make不成功的残余文件清理，之后再make 12make discleanmake make完成后，执行 1make install 出现下图所示即安装成功 配置redis.conf 进入redis-4.0.9,将redis.conf拷贝一份，在拷贝后的上面进行修改将redis.conf拷贝至myredis文件夹下 1vim redis.conf 将no修改为yes 启动redis服务1cd /usr/local/bin 1redis-server /home/myy/hadoop/myredis/redis.config 进入客户端 客户端默认端口为6379 判断是否与服务端连接成功 查看服务状态 关闭连接 关闭后查看服务就没有了 基本命令默认库 Redis默认有16个库，进入时默认在0号库，角标从0开始，某些任务找一号库，某些找二号库，任务逻辑更清晰redis.conf中有说明 转换库的命令，eg：切换为8号库 flushdb和flushall的区别 flushdb是删除当前库，flushall是删除全部库 Benchmark查看本机状态 常用五大数据类型string字符串 String是redis最基本的类型，可以理解为与memcached一摸一样的类型，一个key对应一个value。String类型是二进制安全的，即redis的string可以包含任何数据，比如jpg图片或者序列化对象string是redis最基本的数据类型，一个redis中字符串最多可以是512M hash哈希 redis hash是一个键值对集合，是一个string类型的filed和value的映射表，适合用于存储对象。类似java中的Map&lt;String,Object&gt; list列表 列表是简单的字符串列表，按照插入顺利排序。可以添加一个元素到列表的头部（左边）或者尾部（右边），它的底层实际是个链表 set集合 set是string类型的无序集合。是通过HashTable实现的。 Zset有序集合 Zset（sorted set）zset和set一样也是string类型元素的集合，且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的承宣是唯一的，但分数（score）是可以重复的。 常用关键字set/get/exists/keys/move/mset/mget set设置键值，也可以覆盖原来的值get获取对应键的值exists查看某个key是否存在move移动到别的库内mset/mget批量设置/获取键值 expire/ttl/setex expire设置秒数，过期后自动消失ttl 查看某个key还有多久时间setex设置值时同时设置时间 append/strlen/getrange/setrange/incr/decr/incrby/decrby append补充字符串strlen字符串的长度getrange获取指定区域范围内的值，0到-1表示全部setrange设置指定区域范围内的值incr递增加1decr递减少1incrby decrby自定义数量string类型此命令不可用 lpush/lrange/lpop/rpop/lidex/llen lpush和rpush查看后顺序不同lrange查看listlpop栈顶出去rpop栈底出去lidex索引llen查看list长度 lren/ltrim/rpoplpush/lset/linsert lrem删除n和valueltrim截取指定范围内的值再赋值给listrpoplpush将list01栈底给list02栈顶lset替换某位置的值linsert某值之前或之后插入某值 sadd/smembers/sismember/scard/srem/srandmember sadd设置set集合（重复自动留一个）smembers查看set集合sismember查看set内是否有某值scard获取集合内元素个数srem删除集合内某值srandmember集合中随机出几个数 spop/smove/sdiff/sinter/sunion spop随机出栈smove将一set中某一值赋给另一setsdiff取两集合的差集：在第一个中而不在第二个中sinter取两集合的交集sunion取两集合的并集 zrange/zrevrange/zcount zrange同list相同zrevrange从高到低排序zincrby修改某个值的分数zcount返回指定分数范围内值的个数 hash相关的关键字 kv模式不变，但v是一个键值对]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop 分布式搭建]]></title>
    <url>%2F2018%2F05%2F30%2F20180530hadoop-%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。下面我们一起来搭建吧。 准备工具 linux环境下搭建hadoop集群需要准备：VMware-workstation-10.0.1注册机CentOS-6.5-x86_64-bin-DVD1jdk-7u79-linux-x64hadoop-2.6.4.tar 新建虚拟机 解压VMware-workstation-10.0.1注册机,打开VMware Workstation主页,点击新建虚拟机,选择典型,如下:点击下一步,选择安装程序光盘映像文件,浏览找到你下载CentOS-6.5-x86_64-bin-DVD1的压缩包文件,如下:继续点击下一步,填写用户名和密码(尽量简单),填好后点击下一步,为即将创建的虚拟机命名并选择安装路径(最好不要安装在C盘),如下所示:继续点击下一步至如下界面:点击自定义硬件可以修改虚拟机的各项参数,如果电脑内存小于等于4GB,需要将内存改至512MB,否则严重卡顿。修改完成后点击完成，虚拟机就创建成功，打开后界面如下：若要批量创建虚拟机，可以在创建好的虚拟机的基础上进行克隆操作， 安装jdk 打开一个虚拟机，右键单击桌面选择Open in Terminal，进入编辑界面： 假设用户名为wxx获取root权限123su cd /etcvi sudoers i 进入编辑状态，在 1root ALL=(ALL) ALL的下一行编辑 1wxx ALL=(ALL) ALL 按ESC键，退出编辑格式按Shift + :输入wq!保存并退出 创建hadoop文件夹12cdmkdir hadoop 将jdk-7u79-linux-x64安装包复制到hadoop文件目录下（与windows环境下类似）。 解压jdk-7u79-linux-x64.gz文件123cdcd hadooptar-zxvf jdk-7u79-linux-x64.gz 设置jdk环境变量1234cdcd hadoopsugedit /etc/profile 进入后在最后一行添加以下指令： 123export JAVA_HOME=/home/by/hadoop/jdk1.8.0_11export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 点击保存后关闭，输入以下指令使jdk生效： 1source /etc/profile 检查jdk是否安装成功1java -version 成功后显示如下信息： 123java version "1.7.0_79"Java(TM) SE Runtime Environment (build 1.7.0_79-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode) 创建集群克隆虚拟机 将已经安装好jdk的虚拟机克隆两个，创建三个虚拟机的集群。 修改hostname12suvi /etc/sysconfig/network 将三个虚拟机分别命名master、slave1、slave2如图： 完成后重启虚拟机reboot 将三个虚拟机的ip地址相互连接 首先必须确保虚拟机联网，如果NET模式连不上网，则选中桥接模式。网络通畅后执行以下操作:1.查看三台虚拟机IP,分别对三个虚拟机执行指令ifconfig，查看各虚拟机ip地址 2.在master中执行以下指令 123sucd/etcgedit /etc/hosts 192.168.142.142 192.168.142.143 进入编辑界面后按“IP地址 hostname”填写信息，如图： 填写完后按Save按钮，关闭编辑页。 3.将配置好的文件复制到slave1、slave2中,在master中执行以下指令： 12scp /etc/hosts root@slave1:/etc/scp /etc/hosts root@slave2:/etc/ 4.检查各虚拟机是否互联,在master中执行以下指令： 12ping slave1ping slave2 连通即完成 配置SSH无密钥登录 1.关闭防火墙,对每个虚拟机进行如下操作： 12suchkconfig iptables off 执行后重启虚拟机： 1reboot 2.关闭防火墙后在master下执行以下指令： 1234567cdssh-keygen –t rsacd .sshcat id_rsa.pub &gt;&gt; authorized_keyschmod 600 authorized_keys scp authorized_keys wxx@slave1:~/.ssh/scp authorized_keys wxx@slave2:~/.ssh/ 3.检查无密钥登录是否成功 123ssh slave1ssh slave2ssh master 成功后显示如下： 安装并配置hadoop-2.6.4(在master中) 1.将hadoop-2.6.4.tar.gz安装包复制到hadoop文件目录下（与windows环境下类似）。 2.解压hadoop-2.6.4.tar.gz 123cdcd hadooptar -zxvf hadoop-2.6.4.tar.gz 3.配置hadoop-2.6.4的各项文件 1234cdcd hadoop/hadoop-2.7.4cd etc/hadoopgedit hadoop-env.sh 在最后一行添加: 1export JAVA_HOME=/home/by/hadoop/ jdk1.8.0_11 编辑core-site.xml1gedit core-site.xml 添加代码： 1234567891011121314&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/home/by/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;ds.default.name&lt;/name&gt;&lt;value&gt;hdfs://master:54310&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt; 编辑hdfs-site.xml1gedit hdfs-site.xml 添加代码： 1234567891011121314&lt;property&gt;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;&lt;value&gt;file:/home/by/hadoop/dfs/name&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;&lt;value&gt;file:/home/by/hadoop/dfs/data&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;2&lt;/value&gt;&lt;/property&gt; 编辑mapred-site.xml1gedit mapred-site.xml 注意：必须先复制mapred-site.xml.template文件更名为mapred-site.xml添加代码： 123456789101112&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;&lt;value&gt;master:10020&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;&lt;value&gt;master:19888&lt;/value&gt;&lt;/property&gt; 编辑yarn-site.xml1gedit yarn-site.xml 添加代码： 1234567891011121314151617181920212223242526272829303132&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;&lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;&lt;value&gt;master:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;&lt;value&gt;master:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;&lt;value&gt;master:8031&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;&lt;value&gt;master:8033&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;&lt;value&gt;master:8088&lt;/value&gt;&lt;/property&gt; 编辑master1gedit master 添加代码： 1master 编辑slaves1gedit slaves 添加代码： 123masterslave1slave2 4.将配置好的文件复制到slave1、slave2中 1234cd cd hadoopscp -r hadoop-2.7.4 slave1:~/hadoopscp -r hadoop-2.7.4 slave2:~/hadoop 5.启动集群 123456cdcd hadoop/hadoop-2.7.4bin/hdfs namenode -formatsbin/start-dfs.shsbin/start-yarn.shsbin/hadoop-daemon.sh start secondarynamenode 6.检查集群情况 1jps 三台虚拟机如下所示：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LaTeX入门]]></title>
    <url>%2F2018%2F05%2F27%2F20180527LaTeX%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[LaTeX是一种基于ΤΕΧ的排版系统，由美国计算机学家莱斯利·兰伯特（Leslie Lamport）在20世纪80年代初期开发，利用这种格式，即使使用者没有排版和程序设计的知识也可以充分发挥由TeX所提供的强大功能，能在几天，甚至几小时内生成很多具有书籍质量的印刷品。对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学类文档。这个系统同样适用于生成从简单的信件到完整书籍的所有其他种类的文档。我们在投稿论文的时候，会经常使用LaTex根据期刊的要求对文章进行排版，所以作为一名研究生学习这个是十分必要的。 Hello World 打开WinEdt，建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8。 1234\documentclass&#123;article&#125; \begin&#123;document&#125; hello, world \end&#123;document&#125; 然后在WinEdt的工具栏中找到编译按钮（在垃圾桶和字母B中间），在下拉菜单中选择XeTeX，并点击编译。如果顺利的话，就可以顺利生成出第一个pdf文件，点击工具栏中的放大镜按钮就可以快速打开生成的pdf文件。 标题、作者、章节和段落 建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8，编译并观察现象。 1234567\documentclass&#123;article&#125; \author&#123;My Name&#125; \title&#123;The Title&#125; \begin&#123;document&#125; \maketitle hello, world % This is comment \end&#123;document&#125; 效果图如下： 加入目录 建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8，编译并观察现象。 123456789\documentclass&#123;article&#125; \begin&#123;document&#125; \tableofcontents \section&#123;Hello China&#125; China is in East Asia. \subsection&#123;Hello Beijing&#125; Beijing is the capital of China. \subsubsection&#123;Hello Dongcheng District&#125; \paragraph&#123;Hello Tian'anmen Square&#125;is in the center of Beijing \subparagraph&#123;Hello Chairman Mao&#125; is in the center of Tian'anmen Square \end&#123;document&#125; 效果图如下： 段落和换行123456789101112131415\documentclass&#123;article&#125; \begin&#123;document&#125; Beijing is the capital of China. New York is the capital of America. Amsterdam is \\ the capital \\ of Netherlands. \end&#123;document&#125; 效果图如下： 数学公式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758\documentclass&#123;article&#125; \usepackage&#123;amsmath&#125; \usepackage&#123;amssymb&#125; \begin&#123;document&#125; The Newton's second law is F=ma. The Newton's second law is $F=ma$. The Newton's second law is F=ma The Newton's second law is F=ma Greek Letters $\eta$ and $\mu$ Fraction $\frac&#123;a&#125;&#123;b&#125;$ Power $a^b$ Subscript $a_b$ Derivate $\frac&#123;\partial y&#125;&#123;\partial t&#125; $ Vector $\vec&#123;n&#125;$ Bold $\mathbf&#123;n&#125;$ To time differential $\dot&#123;F&#125;$ Matrix (lcr here means left, center or right for each column) \[ \left[ \begin&#123;array&#125;&#123;lcr&#125; a1 &amp; b22 &amp; c333 \\ d444 &amp; e555555 &amp; f6 \end&#123;array&#125; \right] \] Equations(here \&amp; is the symbol for aligning different rows) \begin&#123;align&#125; a+b&amp;=c\\ d&amp;=e+f+g \end&#123;align&#125; \[ \left\&#123; \begin&#123;aligned&#125; &amp;a+b=c\\ &amp;d=e+f+g \end&#123;aligned&#125; \right. \] \end&#123;document&#125; 效果图如下： 插入图片 先搜索到一个将图片转成eps文件的软件，很容易找的，然后将图片保存为一个名字如figure1.eps。建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8，放在和图片文件同一个文件夹里，编译并观察现象。 12345\documentclass&#123;article&#125; \usepackage&#123;graphicx&#125; \begin&#123;document&#125; \includegraphics[width=4.00in,height=3.00in]&#123;figure1.eps&#125; \end&#123;document&#125; 简单表格123456789101112131415161718192021222324\documentclass&#123;article&#125;\begin&#123;document&#125;\begin&#123;tabular&#125;&#123;|c|c|&#125;a &amp; b \\c &amp; d\\\end&#123;tabular&#125;\begin&#123;tabular&#125;&#123;|c|c|&#125;\hlinea &amp; b \\\hlinec &amp; d\\\hline\end&#123;tabular&#125;\begin&#123;center&#125;\begin&#123;tabular&#125;&#123;|c|c|&#125;\hlinea &amp; b \\ \hlinec &amp; d\\\hline\end&#123;tabular&#125;\end&#123;center&#125;\end&#123;document&#125; 效果图如下：]]></content>
      <categories>
        <category>LaTeX</category>
      </categories>
      <tags>
        <tag>LaTeX</tag>
        <tag>文档编写</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习实战--决策树]]></title>
    <url>%2F2018%2F05%2F25%2F20180525%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[决策树 优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特诊数据缺点：可能会产生过度匹配问题使用数据类型：数值型和标称型专家系统中，经常使用决策树 trees.py12from math import log import operator createDataSet() 创建数据集 trees.py12345678910def createDataSet(): # 数据集中两个特征'no surfacing','flippers', 数据的两个类标签'yes','no #dataSet是个list dataSet = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] labels = ['no surfacing','flippers'] return dataSet, labels calcShannonEnt(dataSet) 计算给定数据集的熵 1234567891011121314151617def calcShannonEnt(dataSet): numEntries = len(dataSet) #计算数据集中实例的总数 labelCounts = &#123;&#125; #创建空字典 for featVec in dataSet: #提取数据集每一行的特征向量 currentLabel = featVec[-1] #获取特征向量最后一列的标签 # 检测字典的关键字key中是否存在该标签，如果不存在keys()关键字，将当前标签/0键值对存入字典中,并赋值为0 #print(labelCounts.keys()) if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0 #print(labelCounts) labelCounts[currentLabel] += 1 #否则将当前标签对应的键值加1 #print("%s="%currentLabel,labelCounts[currentLabel]) shannonEnt = 0.0 #初始化熵为0 for key in labelCounts: prob = float(labelCounts[key])/numEntries #计算各值出现的频率 shannonEnt -= prob * log(prob,2) #以2为底求对数再乘以出现的频率，即信息期望值 #print("%s="%labelCounts[key],shannonEnt) return shannonEnt splitDataSet(dataSet, axis, value) 按照给定特征划分数据集得到熵之后，还需划分数据集，以便判断当前是否正确地划分了数据集，三个输入参数分别为：带划分的数据集，划分数据集的特征，需要返回的特征得值，挑选出dataSet中axis位置值为value的剩余部分。 123456789101112def splitDataSet(dataSet, axis, value): retDataSet = [] for featVec in dataSet: if featVec[axis] == value: #筛选出dataSet中axis位置值为value #列表的索引中冒号的作用，a[1: ]表示该列表中的第1个元素到最后一个元素，而a[ : n]表示从第0歌元素到第n个元素(不包括n) reducedFeatVec = featVec[:axis] #取出特定位置前面部分并赋值给reducedFeatVec #print(featVec[axis+1:]) #print(reducedFeatVec) reducedFeatVec.extend(featVec[axis+1:]) #取出特定位置后面部分并赋值给reducedFeatVec retDataSet.append(reducedFeatVec) #print(retDataSet) return retDataSet chooseBestFeatureToSplit(dataSet) 选择最好的数据集划分方式选取特征，划分数据集，计算得出最好的划分数据集的特征 123456789101112131415161718192021def chooseBestFeatureToSplit(dataSet): numFeatures = len(dataSet[0]) - 1 #计算特征数量，即每一列表元素具有的列数，再减去最后一列为标签，故需减去1 baseEntropy = calcShannonEnt(dataSet) #计算信息熵，此处值为0.9709505944546686，此值将与划分之后的数据集计算的信息熵进行比较 bestInfoGain = 0.0;bestFeature = -1 for i in range(numFeatures): featList = [example[i] for example in dataSet] #创建标签列表 #print(featList) uniqueVals = set(featList) #确定某一特征下所有可能的取值,set集合类型中的每个值互不相同 #print(uniqueVals) newEntropy = 0.0 for value in uniqueVals: #计算每种划分方式的信息熵 subDataSet = splitDataSet(dataSet, i, value) #抽取该特征的每个取值下其他特征的值组成新的子数据集 prob = len(subDataSet)/float(len(dataSet)) #计算该特征下的每一个取值对应的概率（或者说所占的比重） newEntropy += prob * calcShannonEnt(subDataSet) #计算该特征下每一个取值的子数据集的信息熵，并求和 infoGain = baseEntropy - newEntropy #计算每个特征的信息增益 #print("第%d个特征是的取值是%s，对应的信息增益值是%f"%((i+1),uniqueVals,infoGain)) if (infoGain &gt; bestInfoGain): bestInfoGain = infoGain bestFeature = i #print("第%d个特征的信息增益最大，所以选择它作为划分的依据，其特征的取值为%s,对应的信息增益值是%f"%((i+1),uniqueVals,infoGain)) return bestFeature majorityCnt(classList) 递归构建决策树，返回出现次数最多的分类名称 1234567def majorityCnt(classList): classCount=&#123;&#125; for vote in classList: if vote not in classCount.keys(): classCount[vote] = 0 classCount[vote] += 1 sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True) return sortedClassCount[0][0] createTree(dataSet,labels) 创建树,参数为数据集和标签列表 123456789101112131415161718192021def createTree(dataSet,labels): classList = [example[-1] for example in dataSet] #提取dataset中的最后一列——种类标签 #print(classList) if classList.count(classList[0]) == len(classList): #计算classlist[0]出现的次数,如果相等，说明都是属于一类，不用继续往下划分 return classList[0] #递归结束的第一个条件是所有的类标签完全相同，则直接返回该类标签 #print(dataSet[0]) if len(dataSet[0]) == 1: #看还剩下多少个属性，如果只有一个属性，但是类别标签有多个，就直接用majoritycnt()进行整理，选取类别最多的作为返回值 return majorityCnt(classList) #递归结束的第二个条件是使用完了所有的特征，仍然不能将数据集划分成仅包含唯一类别的分组，则返回出现次数最多的类别 bestFeat = chooseBestFeatureToSplit(dataSet) #选取信息增益最大的特征作为下一次分类的依据 bestFeatLabel = labels[bestFeat] #选取特征对应的标签 #print(bestFeatLabel) myTree = &#123;bestFeatLabel:&#123;&#125;&#125; #创建tree字典，下一个特征位于第二个大括号内，循环递归 del(labels[bestFeat]) #删除使用过的特征 featValues = [example[bestFeat] for example in dataSet] #特征值对应的该栏数据 #print(featValues) uniqueVals = set(featValues) #找到featvalues所包含的所有元素，去重复 for value in uniqueVals: subLabels = labels[:] #将使用过的标签删除更新后，赋值给新的列表，进行迭代 #print(subLabels) myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat,value),subLabels) #循环递归生成树 return myTree classify(inputTree,featLabels,testVec): 测试算法，使用决策树执行分类 12345678910111213def classify(inputTree,featLabels,testVec): firstStr = list(inputTree.keys())[0] #找到树的第一个分类特征，或者说根节点'no surfacing' #print(firstStr) secondDict = inputTree[firstStr] #从树中得到该分类特征的分支，有0和1 #print(secondDict) featIndex = featLabels.index(firstStr) #根据分类特征的索引找到对应的标称型数据值，'no surfacing'对应的索引为0 #print(featIndex) key = testVec[featIndex] valueOfFeat = secondDict[key] if isinstance(valueOfFeat, dict): classLabel = classify(valueOfFeat, featLabels, testVec) else: classLabel = valueOfFeat return classLabel storeTree(inputTree,filename) 决策树的存储，使用pickle序列化对象，可在磁盘中保存对象。 12345678910def storeTree(inputTree,filename): import pickle fw = open(filename,'wb') #二进制写入'wb' pickle.dump(inputTree,fw) #pickle的dump函数将决策树写入文件中 fw.close() def grabTree(filename): import pickle fr = open(filename,'rb') #对应于二进制方式写入数据，'rb'采用二进制形式读出数据 return pickle.load(fr) trees_main.py123import treesfrom imp import reloadimport treePlotter 创建数据集1234myDat,labels=trees.createDataSet()#print(myDat)#print(labels)#print(trees.calcShannonEnt(myDat)) 熵增大的原因 熵越高，混合的数据就越多，如果我们在数据集中添加更多的分类，会导致熵结果增大 123#myDat[1][-1]='maybe'#更改list中某一元素的值（除yes和no外的值），即为添加更多的分类，中括号中为对应元素行列的位置#print(myDat)#print(trees.calcShannonEnt(myDat)) #分类变多，熵增大 append()和extend()两类方法的区别123456a=[1,2,3]b=[4,5,6]a.append(b)#print(a)#[1, 2, 3, [4, 5, 6]]a.extend(b)#print(a)#[1, 2, 3, [4, 5, 6], 4, 5, 6] 按照给定特征划分数据集123#print(myDat)#print(trees.splitDataSet(myDat,0,1))#print(trees.splitDataSet(myDat,0,0)) 选择最好的数据集划分方式12#print(myDat)#print(trees.chooseBestFeatureToSplit(myDat)) 创建树,参数为数据集和标签列表12345678myTree=trees.createTree(myDat,labels)#print(myTree)myDat,labels=trees.createDataSet()myTree1=treePlotter.retrieveTree(0) #print(myTree1)#print(trees.classify(myTree1,labels,[1,0]))#print(trees.classify(myTree,labels,[1,1])) 决策树的存储12trees.storeTree(myTree,'classifierStorage.txt')#print(trees.grabTree('classifierStorage.txt')) 使用决策树预测隐形眼镜类型123456fr=open('lenses.txt')lenses = [inst.strip().split('\t') for inst in fr.readlines()] #将文本数据的每一个数据行按照tab键分割，并依次存入lenseslensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate'] # 创建并存入特征标签列表lensesTree = trees.createTree(lenses, lensesLabels) # 根据继续文件得到的数据集和特征标签列表创建决策树print(lensesTree)treePlotter.createPlot(lensesTree) treePlotter.py python中使用Matplotlib注解绘制树形图 1import matplotlib.pyplot as plt 定义文本框和箭头格式123decisionNode = dict(boxstyle="sawtooth", fc="0.8") # boxstyle为文本框的类型，sawtooth是锯齿形，fc是边框线粗细,pad指的是外边框锯齿形（圆形等）的大小leafNode = dict(boxstyle="round4", fc="0.8") #定义决策树的叶子结点的描述属性，round4表示圆形arrow_args = dict(arrowstyle="&lt;-") #定义箭头属性 plotNode(nodeTxt, centerPt, parentPt, nodeType) 绘制带箭头的注解annotate是关于一个数据点的文本nodeTxt为要显示的文本，centerPt为文本的中心点，箭头所在的点，parentPt为指向文本的点annotate的作用是添加注释，nodetxt是注释的内容nodetype指的是输入的节点（边框）的形状 1234def plotNode(nodeTxt, centerPt, parentPt, nodeType): createPlot.ax1.annotate(nodeTxt, xy=parentPt, xycoords='axes fraction', xytext=centerPt, textcoords='axes fraction', va="center", ha="center", bbox=nodeType, arrowprops=arrow_args ) def createPlot(): 第一版构造树函数，后面会改进，所以这里要注释上 123456#fig = plt.figure(1, facecolor='white')#fig.clf()#createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses#plotNode('a decision node', (0.5, 0.1), (0.1, 0.5), decisionNode)#plotNode('a leaf node', (0.8, 0.1), (0.3, 0.8), leafNode)#plt.show() getNumLeafs(myTree) 计算叶子节点的个数构造注解树，需要知道叶节点的个数，以便可以正确确定x轴的长度；要知道树的层数，可以确定y轴的高度。 1234567891011121314151617181920212223def getNumLeafs(myTree): numLeafs = 0 firstStr = list(myTree.keys())[0] #获得myTree的第一个键值，即第一个特征，分割的标签 #print(firstStr) secondDict = myTree[firstStr] #根据键值得到对应的值，即根据第一个特征分类的结果 #print(secondDict) for key in secondDict.keys(): #获取第二个小字典中的key if type(secondDict[key]).__name__=='dict': #判断是否小字典中是否还包含新的字典（即新的分支） numLeafs += getNumLeafs(secondDict[key]) #包含的话进行递归从而继续循环获得新的分支所包含的叶节点的数量 else: numLeafs +=1 #不包含的话就停止迭代并把现在的小字典加一表示这边有一个分支 return numLeafsdef getTreeDepth(myTree): #计算判断节点的个数 maxDepth = 0 firstStr = list(myTree.keys())[0] secondDict = myTree[firstStr] for key in secondDict.keys(): if type(secondDict[key]).__name__=='dict': thisDepth = 1 + getTreeDepth(secondDict[key]) else: thisDepth = 1 if thisDepth &gt; maxDepth: maxDepth = thisDepth return maxDepth retrieveTree(i) 预先存储树信息 12345def retrieveTree(i): listOfTrees =[&#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: 'no', 1: 'yes'&#125;&#125;&#125;&#125;, &#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: &#123;'head': &#123;0: 'no', 1: 'yes'&#125;&#125;, 1: 'no'&#125;&#125;&#125;&#125; ] return listOfTrees[i] plotMidText(cntrPt, parentPt, txtString) 作用是计算tree的中间位置，cntrPt起始位置,parentPt终止位置,txtString文本标签信息 12345678910111213141516171819202122def plotMidText(cntrPt, parentPt, txtString): xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0] #cntrPt起点坐标，子节点坐标，parentPt结束坐标，父节点坐标 yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1] #找到x和y的中间位置 createPlot.ax1.text(xMid, yMid, txtString, va="center", ha="center", rotation=30)def plotTree(myTree, parentPt, nodeTxt): numLeafs = getNumLeafs(myTree) depth = getTreeDepth(myTree) firstStr = list(myTree.keys())[0] cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff) #计算子节点的坐标 plotMidText(cntrPt, parentPt, nodeTxt) #绘制线上的文字 plotNode(firstStr, cntrPt, parentPt, decisionNode) #绘制节点 secondDict = myTree[firstStr] plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD #每绘制一次图，将y的坐标减少1.0/plottree.totald，间接保证y坐标上深度的 for key in secondDict.keys(): if type(secondDict[key]).__name__=='dict': plotTree(secondDict[key],cntrPt,str(key)) else: plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode) plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key)) plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD createPlot(inTree)1234567891011def createPlot(inTree): fig = plt.figure(1, facecolor='white') #类似于Matlab的figure，定义一个画布，背景为白色 fig.clf() # 把画布清空 axprops = dict(xticks=[], yticks=[]) #subplot定义了一个绘图 createPlot.ax1 = plt.subplot(111, frameon=False, **axprops) #no ticks #createPlot.ax1为全局变量，绘制图像的句柄，111表示figure中的图有1行1列，即1个，最后的1代表第一个图,frameon表示是否绘制坐标轴矩形 plotTree.totalW = float(getNumLeafs(inTree)) plotTree.totalD = float(getTreeDepth(inTree)) plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0; plotTree(inTree, (0.5,1.0), '') plt.show() treePlotter_main.py12345678import treePlotter#treePlotter.createPlot()#print(treePlotter.retrieveTree(1))myTree=treePlotter.retrieveTree(0)#print(treePlotter.getNumLeafs(myTree))#print(treePlotter.getTreeDepth(myTree))myTree['no surfacing'][3]='maybe'treePlotter.createPlot(myTree)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>《机器学习实战》</tag>
        <tag>ML</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习实战--KNN]]></title>
    <url>%2F2018%2F05%2F23%2F20180523%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-KNN%2F</url>
    <content type="text"><![CDATA[这本书的好就不多说的，其实如果不是因为机器学习那门学位课的作业是这个，我想我会错过这本书0.0 knn 优 点：精度高，对异常值不敏感，无数据输入假定缺 点：计算复杂度高，空间复杂度高，无法给出数据的内在含义使用数据范围：数值型和标称型 ————————————————————————————-下面进入正题————————————————————————————- kNN.py123from numpy import * import operator from os import listdir createDataSet()1234def createDataSet(): group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]]) labels = ['A','A','B','B'] return group, labels classify0() inX用于分类的输入向量,是一个向量dataSet输入的训练样本集，是一个矩阵labels标签向量k用于选择最近邻居的数目labels数目与dataSet的行数相同 1234567891011121314151617181920212223242526272829def classify0(inX, dataSet, labels, k): dataSetSize = dataSet.shape[0] #返回的是dataSet的行数，行数就是样本的数量 diffMat = tile(inX, (dataSetSize,1)) - dataSet #矩阵相减 #inX是个向量，而dataset是个矩阵，两者之间要进行相减的运算，需要把这个向量也补成一个和dataset有相同行数列数的矩阵， #tile()的第二个参数，就是(datasetsize,1)，这个参数的意思就是把inX补成有datasetsize行数的矩阵。 #假如inX是（1，2），datasetsize =3，那么经过tile()转换后产生了一个这样的矩阵（[1,2],[1,2],[1,2]） sqDiffMat = diffMat**2 #平方 sqDistances = sqDiffMat.sum(axis=1) #按行求和 # sqdiffMat是([1,2],[0,1],[3,4])，axis这个参数影响了对矩阵求和时候的顺序，axis=0是按照列求和，结果为([3.1.7]) # axis=1是按照行进行求和，结果是([4,7])。 distances = sqDistances**0.5 #开方，得到欧氏距离 sortedDistIndicies = distances.argsort() #把向量中每个元素进行排序，结果是元素的索引形成的向量 #例子distance([1,4,3])，经过distance.argsort()之后的结果是([0,2,1] classCount=&#123;&#125; #存放最终的分类结果及相应的结果投票数 #投票过程，就是统计前k个最近的样本所属类别包含的样本个数 for i in range(k): # index = sortedDistIndicies[i]是第i个最相近的元素索引，即样本下标 # voteIlabel = labels[index]是样本index对应的分类结果('A' or 'B') voteIlabel = labels[sortedDistIndicies[i]] # classCount.get(voteIlabel, 0)返回voteIlabel的值，如果不存在，则返回0 # 然后将票数增1 classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 # 把分类结果进行排序，然后返回得票数最多的分类结果 # key=operator.itemgetter(1)的意思是按照字典里的第一个排序 #例子a = [1, 2, 3]，b = operator.itemgetter(1)，b(a)返回为2 #b = operator.itemgetter(1, 0)，b(a)，定义函数b，获取对象的第1个域和第0个的值，返回 (2, 1) # reverse=True是降序排序 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) return sortedClassCount[0][0] #返回类别最多的类别 file2matrix() 将文本记录转换为NumPy将文本记录转换为NumPy的解析程序输入为矩阵，输出为训练样本矩阵和类标签向量 12345678910111213141516def file2matrix(filename): fr = open(filename) #打开文档 numberOfLines = len(fr.readlines()) #得到文件行数 #fr.readlines()读取行数,存在数组中,导入后每行中用\t隔开,两行之间用\n换行得到文件行数 returnMat = zeros((numberOfLines,3)) #创建返回NumPy矩阵，numberoflines行，3列的初始化零的矩阵 classLabelVector = []#定义一个空的数组 fr = open(filename) index = 0 for line in fr.readlines(): line = line.strip() #删除（）中的内容，这里表示删除空格 listFromLine = line.split('\t')#以\t分割 #print(listFromLine) returnMat[index,:] = listFromLine[0:3]#把每行前三个元素存入returnMat矩阵中，每行中存储三个 classLabelVector.append(int(listFromLine[-1]))#存储第四列元素即标签，在数组中append添加，-1表示最后一列 index += 1 return returnMat,classLabelVector autoNorm() 归一化数值，避免某特征值过大，使得权重比例不均匀，对计算结果产生影响。autoNorm可以自动将数字特征值转化为0到1区间 12345678910111213def autoNorm(dataSet): minVals = dataSet.min(0)#一维数组，值为各项特征（列）中的最小值。参数0使得函数从列中选取最小值 #print(minVals) maxVals = dataSet.max(0) #print(maxVals) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) #创建与样本集一样大小的零矩阵 #print(normDataSet) m = dataSet.shape[0]#dataSet的行数 normDataSet = dataSet - tile(minVals, (m,1))#矩阵中所有的值减去最小值 #tile将原来的一个数组minVals，扩充成了m行1列的数组 normDataSet = normDataSet/tile(ranges, (m,1)) #矩阵中所有的值除以最大取值范围进行归一化 return normDataSet, ranges, minVals datingClassTest() 测试算法，样本集中百分之九十的数据用来训练样本，百分之十的样本用来测试分类器kNN.classify0()。 1234567891011121314def datingClassTest(): hoRatio = 0.10 #百分之十的数据用于测试分类器，更改该变量的值可更改参加测试分类器的数据量 datingDataMat,datingLabels = file2matrix('datingTestSet2.txt') #导入数据 normMat, ranges, minVals = autoNorm(datingDataMat) #归一化数值 m = normMat.shape[0] #得到总行数 numTestVecs = int(m*hoRatio) #测试总数据数量，m*hoRatio是一个浮点型，需转化成整形 errorCount = 0.0 #初试错误率为0 for i in range(numTestVecs): classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) #分类器（需要测试的向量，训练样本集(90%)，标签集合，K） print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 #计数，错误的个数 print("the total error rate is: %f" % (errorCount/float(numTestVecs))) #错误率 print(errorCount) classifyPerson() 约会数据,对于未来的约会预测函数，输入飞行里程数，玩视频游戏的百分比和冰激凌公升数，可以得到一个是否对他感兴趣的预测 123456789101112131415161718192021222324252627def classifyPerson(): resultList=['not at all','in samll doses','in large doses'] #三种感兴趣程度 percentTats=float(input("percentage of time spent playing video games?")) ffMiles=floats=float(input("frequent flier miles earned per year?")) iceCream=float(input("liters of ice cream consuned per year?"))#input键盘输入 datingDataMat,datingLabels=file2matrix('datingTestSet2.txt') # 导入数据 normMat,ranges,minvals=autoNorm(datingDataMat) # 归一化，ranges是归一化的分母 inArr=array([ffMiles,percentTats,iceCream]) # inArr是归一化之前的datingDataMat数组中的行 classifierResult=classify0((inArr-minvals)/ranges,normMat,datingLabels,3)#先归一化，然后调用分类函数 #print(classifierResult) print("you will probably like this person:%s"%resultList[classifierResult-1])``` ## img2vector()&gt; 图片转向量手写体：32*32的黑白图像图片转向量，将32*32的二进制图像矩阵转换为1*1024的向量```pythondef img2vector(filename): returnVect = zeros((1,1024)) fr = open(filename) for i in range(32):#循环读出文件的前32行 lineStr = fr.readline() for j in range(32):#将每行的前32个字符存储在NumPy数组中 returnVect[0,32*i+j] = int(lineStr[j]) return returnVect#返回数组 handwritingClassTest() 手写体测试 123456789101112131415161718192021222324252627def handwritingClassTest(): hwLabels = [] trainingFileList = listdir('trainingDigits') #导入训练数据 #print(trainingFileList) m = len(trainingFileList) #训练数据的总数 #print(m) trainingMat = zeros((m,1024)) #m行1024列的零向量 for i in range(m): fileNameStr = trainingFileList[i] #文件名 fileStr = fileNameStr.split('.')[0] #取文件名.之前的名字 classNumStr = int(fileStr.split('_')[0]) #取文件名_之前的名字 hwLabels.append(classNumStr) trainingMat[i,:] = img2vector('trainingDigits/%s' % fileNameStr) #将对应数据集下的文件一个个的转为向量 #print(trainingMat[i,:]) testFileList = listdir('testDigits') #测试数据 errorCount = 0.0 mTest = len(testFileList) for i in range(mTest): fileNameStr = testFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) vectorUnderTest = img2vector('testDigits/%s' % fileNameStr) classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3) #利用训练的trainingMat测试 print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, classNumStr)) if (classifierResult != classNumStr): errorCount += 1.0 print("\nthe total number of errors is: %d" % errorCount) print("\nthe total error rate is: %f" % (errorCount/float(mTest))) knn_main.py1234567891011import kNN import matplotlib import matplotlib.pyplot as plt import numpy as np from imp import reload group,labels=kNN.createDataSet() #print(group) #print(labels) #print(kNN.classify0([0,0],group,labels,3)) 散点图123456789fig=plt.figure() #建立画板 ax=fig.add_subplot(111) #添加一个子图，一行一列第一个子块，若括号内为349，则三行四列第9个子块 reload(kNN) datingDataMat,datingLabels=kNN.file2matrix('datingTestSet2.txt') #print(datingDataMat) #ax.scatter(datingDataMat[:,1],datingDataMat[:,2]) # scatter绘制散点图,使用第二列第三列数据 #ax.scatter(datingDataMat[:,1],datingDataMat[:,2],15.0*np.array(datingLabels),15.0*np.array(datingLabels)) ax.scatter(datingDataMat[:,0],datingDataMat[:,1],15.0*np.array(datingLabels),15.0*np.array(datingLabels)) #plt.show() 归一化数值1234normMat,ranges,minVals=kNN.autoNorm(datingDataMat) #print(normMat) #print(ranges) #print(minVals) 测试算法1#kNN.datingClassTest() 约会预测123#对于未来的约会预测函数，输入飞行里程数，玩视频游戏的百分比和冰激凌公升数，可以得到一个是否对他感兴趣的预测， #输入10 10000 0.5 #kNN.classifyPerson() 手写体1234567#trainingDigits包含大约2000个例子，每个数字约有200个样本 #testDigits包含大约900个测试数据 testVector=kNN.img2vector('trainingDigits/0_13.txt') #print(testVector[0,0:31]) #print(testVector[0,32:63]) #print(testVector[0,64:95]) kNN.handwritingClassTest()]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>《机器学习实战》</tag>
        <tag>ML</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伊始]]></title>
    <url>%2F2018%2F05%2F17%2F20180517%E4%BC%8A%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[Welcome to AmberWu’s Blog! 为什么会想弄这么一个博客呢，还不是因为有那么一个研究僧程序猿且男屌丝，哦不不不，大神，嗯，大神0.0。第一次接触建站域名，随便弄弄。还挺有意思的，本以为这个很难，离自己很远，动起手来，真的蛮简单的，毕竟，本学渣弄得下来，哈哈哈 简单随便说说建站方法Hexo 就是以Hexo为主，剩下的自行百度吧，毕竟我要回寝室，没时间写了 Github Pages 以github为载体实现的，也百度吧，啊啊啊，实验室就剩我自己了。 配置域名 在博客的根目录下source文件中(例如：C:\hexo\source)新建一个名为CNAME的文件，注意没有任何后缀，用于github进行读取。在文件中添加自己的域名并保存，例如 1amberwu.top 然后，重新生成静态文件并部署。CNAME文件也会被上传到github仓库当中，此时在浏览器中输入自己的域名，回车之后，你会第一次遇见自己的小天地~ Hexo的一些基本命令123hexo clean #用于清除配置文件hexo g #完整命令为hexo generate,用于生成静态文件hexo s #完整命令为hexo server,用于启动服务器，主要用来本地预览 在浏览器地址栏输入http://localhost:4000/, 按下回车键，熟悉的界面又出现了。 12hexo d #完整命令为hexo deploy,用于将本地文件发布到github等git仓库上hexo n "my article" #完整命令为hexo new,用于新建一篇名为“my article”的文章 这样就会在博客目录下source_posts中生成相应的 my article.md文件( 例如 C:\blog\source_posts\my article.md ) Hexo修改及配置主题 hexo初始化之后默认的主题是landscape , 然后你可以去这个地址 https://hexo.io/themes/ 里面找到你想要的主题。在github中搜索你要的主题名称，里面都会有该主题的如何使用的介绍，按着来就好了，反正就是改改改！我选的是next,看起来挺不错，至少是我喜欢的类型。 更改主题需要修改配置文件 更改主题需要修改配置文件，就是根目录下的_config.yml文件，找到 theme 字段，并将其值更改为next即可 1theme: next 配置next主题 next主题共分三种，在站点根目录/themes/next/_congig.yml 文件中修改，找到scheme关键字即可选择。 1234# Schemes#scheme: Muse#scheme: Mistscheme: Pisces 当然，你完全可以进行很多的自定义设置甚至修改源码，定制自己的主题。小女子能力有限，更多的设置请参考官方文档http://theme-next.iissnan.com/getting-started.html 添加背景图片 将背景图片命名为background.jpg并放入主题根目录/source/images文件夹中打开博客根目录/themes/next/source/css/_custom/custom.styl文件加入如下代码： 123456// Custom styles.body &#123; background-image: url(/images/background.jpg); background-attachment: fixed; background-repeat: no-repeat;&#125; 更多资料]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
