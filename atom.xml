<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AmberWu</title>
  
  <subtitle>尽人事，听天命</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://moyingyao.github.io/"/>
  <updated>2018-06-08T09:31:45.306Z</updated>
  <id>http://moyingyao.github.io/</id>
  
  <author>
    <name>AmberWu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基础网络</title>
    <link href="http://moyingyao.github.io/2018/06/07/%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C/"/>
    <id>http://moyingyao.github.io/2018/06/07/基础网络/</id>
    <published>2018-06-07T11:13:30.000Z</published>
    <updated>2018-06-08T09:31:45.306Z</updated>
    
    <content type="html"><![CDATA[<p>LeNet    AlexNet    ResNet<br><a id="more"></a></p><h1 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h1><p>1989年LeCun提出的，是卷积神经网络的鼻祖。<br>网络结构示意图如下：<br><img src="https://i.imgur.com/YFQgoQ7.png" alt=""><br>第一层卷积核为5 x 5，stride为1，输出通道为20，分辨率为24 x 24（28-5+1=24）的特征响应图。经过2 x 2池化，分辨率降为12 x 12。然后同样的操作，通道数变为50 x 50，分辨率变为4 x 4。最后全连接，第一层单元数为500，第二层输出分类个数10，再接softmax输出最终结果。</p><h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p>AlexNet针对的是ILSVRC的分类问题，输入图片是256 x 256的三通道彩色图片。参数有6000多万（其中全连接的参数占了约94%）</p><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>训练Alex的时候采用了数据增加手段，包含随机位置裁剪，具体就是在256 x 256的图片中，随机产生位置裁剪一块224 x 224的子区域。<br>且在卷积过程中使用了零填充。<br><img src="https://i.imgur.com/gZryFAR.png" alt=""><br>值得注意的是，conv2和conv4，conv5的两个分叉。这样做主要是因为当时Alex的显卡不够强大，为了减少计算量同时方便并行，所以采用了分组计算。另外，fc6和fc7使用了dropout。</p><h1 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h1><p>将层数推进到了22层，而且创新的提出了构件网络的单元Inception模块。参数总量不到700万。</p><h2 id="Network-In-Network-NIN"><a href="#Network-In-Network-NIN" class="headerlink" title="Network In Network(NIN)"></a>Network In Network(NIN)</h2><p>1 x 1卷积相当于对所有的输入特征响应图做了一次线性组合，然后输出新的一组特征响应图。</p><h2 id="Inception结构"><a href="#Inception结构" class="headerlink" title="Inception结构"></a>Inception结构</h2><p>Inception模块示意图如下图所示：<br><img src="https://i.imgur.com/LLM4Qp9.png" alt=""><br>因为所有卷积的stride都是1，所以在图中没有特意标明，另外对于3 x3卷积，5 x 5卷积和3 x 3池化，为了保持特征响应图大小一直，都用了零填充（3 x3卷积填充为1，5 x 5的填充为2）。<br>在输出前有个concatenate层，直译过来就是“并置”。这个操作的意思是把4组不同类型但是大小相同的特征响应图一张张“并排叠”一起，形成新的一组特征响应图。<br>所以通过上图可以看到，Inception里面主要做了两件事：第一件事是通过1 x 1,3 x 3,5 x 5这三种不同尺度的卷积核，一共四种方式对输入的特征响应图做了特征抽取。第二件事是为了降低计算量，同时让信息通过更少的连接传递以达到更加稀疏的特性，采用1 x 1卷积核进行降维。可以看到，对于计算量略大的3 x 3卷积，把192通道的特征响应图降到了原来的一半96通道，对于更大计算量的5 x 5卷积，则降到了更少的16通道。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>共22层<br><img src="https://i.imgur.com/un4kUvM.png" alt=""><br>1.3个loss单元，就是训练中计算代价函数的对应单元，目的是为了帮助网咯的收敛。<br>2.最后一个Inception模块输出7 x 7大小的832通道的特征响应图后，并没有像AlexNet那样降维然后过两个全连接，而是直接对每个特征响应图求了平均值，得到了一个1024维的向量，然后再过一个全连接得到和输出数目对应的1000维向量用于分类，从某种程度上讲，这算是舍弃了经典的最后一/二层全连接的做法。大大减少了参数量。</p><h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p>2015年何恺明构建了残差网络。比较经典的ResNet一般是3种结构：50层、101层、152层<br><a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener">https://github.com/KaimingHe/deep-residual-networks</a></p><h2 id="退化问题"><a href="#退化问题" class="headerlink" title="退化问题"></a>退化问题</h2><p>随着层数的加深到一定程度之后，越深的网络反而效果越差，尽管已经有了很多有效的办法，但梯度的衰减仍然存在。</p><h2 id="残差单元"><a href="#残差单元" class="headerlink" title="残差单元"></a>残差单元</h2><p>残差指的是预测值和观测值之间的差异，误差是值观测值和真实值之间的差异，不要弄混了。<br>为了解决退化问题，提出了残差模块，大体思路为，既然单位映射在梯度下降框架下不起作用，那么索性直接把输入传到输出端，“强行”作为单位映射的部分，让可学习的网络作为另一部分，这就是残差学习的模块。如下图中a所示。<br><img src="https://i.imgur.com/gfLxNG7.png" alt=""><br>可以看到，数据经过了两条路线，一条是和一般网络类似的经过两个卷积层再传递到输出，另一条是实现单位映射的直线连接路线，这个路线被称为shortcut。这样做之后，如果像前面说的那样，前面层的参数已经达到了一个很好的水平，那么再基本构建模块时，输入的信息通过shortcut得以一定程度的保留。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LeNet    AlexNet    ResNet&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://moyingyao.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="神经网络" scheme="http://moyingyao.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>数据集介绍</title>
    <link href="http://moyingyao.github.io/2018/06/07/%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/"/>
    <id>http://moyingyao.github.io/2018/06/07/数据集介绍/</id>
    <published>2018-06-07T11:05:33.000Z</published>
    <updated>2018-06-07T11:14:49.663Z</updated>
    
    <content type="html"><![CDATA[<p>MNIST–深度学习入门者必用Hello Worle级的数据<br><a id="more"></a><br>MNIST手写体数据集，全称是Mixed National Institute of Standards and Technology。<br>共70000个样本，其中60000个训练集，10000个测试集。<br>均为分辨率为28*28的灰度图，其中一半是书写比较工整的，另一半是相对潦草的，这两种书写在训练集和测试集中也分别占一半。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MNIST–深度学习入门者必用Hello Worle级的数据&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://moyingyao.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="数据集" scheme="http://moyingyao.github.io/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper</title>
    <link href="http://moyingyao.github.io/2018/05/27/zookeeper/"/>
    <id>http://moyingyao.github.io/2018/05/27/zookeeper/</id>
    <published>2018-05-27T13:54:25.000Z</published>
    <updated>2018-05-27T14:02:41.762Z</updated>
    
    <content type="html"><![CDATA[<p>zookeeper 主要是写分布式程序<br>可总结为：一致、有头、数据数<br><a id="more"></a></p><h1 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h1><p>使用zookeeper开发自己的分布式系统要注意的问题：</p><ol><li>解决数据一致性的问题</li><li>协调各种“动物”<br>hadoop  小象<br>impala  黑斑羚<br>shark   鲨鱼<br>hive    蜂巢<br>mahout  象夫<br>zookeeper 动物园管理员</li></ol><h1 id="google三论文"><a href="#google三论文" class="headerlink" title="google三论文"></a>google三论文</h1><p>GFS → HDFS<br>BigTable → HBase<br>MapReduce → HadoopMR<br>chubby → zookeeper</p><h1 id="zookeeper是什么？"><a href="#zookeeper是什么？" class="headerlink" title="zookeeper是什么？"></a>zookeeper是什么？</h1><p>NoSQL数据库<br>CAP原理</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;zookeeper 主要是写分布式程序&lt;br&gt;可总结为：一致、有头、数据数&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="大数据相关" scheme="http://moyingyao.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="zookeeper" scheme="http://moyingyao.github.io/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>物体检测</title>
    <link href="http://moyingyao.github.io/2018/05/27/%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E5%85%A5%E9%97%A8/"/>
    <id>http://moyingyao.github.io/2018/05/27/物体检测入门/</id>
    <published>2018-05-27T13:38:38.000Z</published>
    <updated>2018-05-27T14:00:09.994Z</updated>
    
    <content type="html"><![CDATA[<p>只是了解一点点，就写在这里了，后续陆续更新<br><a id="more"></a><br>物体检测  object-detection<br>分类+位置<br>14年开始热门起来</p><h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><p>基于区域的CNN<br>步骤：</p><ol><li>随机扣一块区域，输入至CNN，看是否为想要识别的物体，选择性搜索、出框，一般2000次</li><li>将框Resize改变成同样大小的框</li><li>输入至CNN中，生成256*256的图像</li><li>使用SVM分类</li></ol><h1 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h1><p>进步：将起初的先出框再卷积改为先卷积再出框，减少了卷积次数<br>步骤：</p><ol><li>先卷积，再出框，一般为2000个区域</li><li>ROI Pooling框出区域，值取max</li><li>softmax，多类输出</li></ol><p>RPI Pooling需要输入：</p><ol><li>卷积后的结果</li><li>生成区域框的边框，标签为左下角和右上角的坐标</li></ol><h1 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h1><h1 id="SSD单发多框检测器"><a href="#SSD单发多框检测器" class="headerlink" title="SSD单发多框检测器"></a>SSD单发多框检测器</h1><p>图片 → 卷积 → 出框<br>softmax  →n+1分类（n类+背景）→ 卷积 → 出框</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;只是了解一点点，就写在这里了，后续陆续更新&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://moyingyao.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="物体检测" scheme="http://moyingyao.github.io/tags/%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>memcached安装及简单命令</title>
    <link href="http://moyingyao.github.io/2018/05/25/memcached%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4/"/>
    <id>http://moyingyao.github.io/2018/05/25/memcached安装及简单命令/</id>
    <published>2018-05-25T12:09:14.000Z</published>
    <updated>2018-05-25T12:52:05.663Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ubuntu16-0-4下memcached的安装"><a href="#ubuntu16-0-4下memcached的安装" class="headerlink" title="ubuntu16.0.4下memcached的安装"></a>ubuntu16.0.4下memcached的安装</h1><a id="more"></a><p>linux系统安装memcached首先要安装libevent库</p><pre><code>sudo apt-get install libevent-devesudo apt-get install memcached</code></pre><p>若linux系统为centos则命令为</p><pre><code>yum install libevent libevent-deveyum install memcached</code></pre><h1 id="memcached的连接与关闭"><a href="#memcached的连接与关闭" class="headerlink" title="memcached的连接与关闭"></a>memcached的连接与关闭</h1><h2 id="启动memcached连接"><a href="#启动memcached连接" class="headerlink" title="启动memcached连接"></a>启动memcached连接</h2><p>找到memcached的安装目录，自动安装memcached在/usr/local/bin/memcached路径下</p><pre><code>memcached -u root -d -m 128m -p 11211</code></pre><p>连接memcached语法为：telnet HOST PORT<br>本实例的memcached服务运行的主机为127.0.0.1(本机)，端口为11211</p><pre><code>telnet 127.0.0.1 11211</code></pre><p>连接成功如下图所示：<img src="https://i.imgur.com/jLWKbvn.png" alt=""><br>退出命令</p><pre><code>quit</code></pre><h2 id="关闭memcached"><a href="#关闭memcached" class="headerlink" title="关闭memcached"></a>关闭memcached</h2><p>与windows直接输入memcached.exe -d stop关闭memcached不同<br>linux需先知道memcached的进程号，再将其杀死<br>查看进程号</p><pre><code>stats     或者     ps -ef|grep memcached</code></pre><p>知道了memcached对应的进程号pid后，使用kill命令杀死进程即可。<br>注意：杀死进程前必须quit退出连接</p><pre><code>kill 5070</code></pre><p>杀死进城后再次连接memcached失败，说明memcached已经被关闭。</p><h1 id="memcached的命令"><a href="#memcached的命令" class="headerlink" title="memcached的命令"></a>memcached的命令</h1><h2 id="存储命令"><a href="#存储命令" class="headerlink" title="存储命令"></a>存储命令</h2><p>1.set<br>set用于将value存储于key中，若set的key已经存在，该命令可以更新key所对应的原来的数据。语法格式如下：</p><pre><code>set key flag exptime bytes [noreply]value</code></pre><p>key：键值对中的key，用于查找缓存值<br>flag：可以包含键值对的整型参数，客户机使用它存储关于键值对的额外信息<br>exptime：再缓存中保存键值对的时间长度，以秒为单位，0表示永远<br>bytes：在缓存中存储的字节数<br>noreply：可选参数，该参数告知服务器不需要返回数据<br>value：存储的值，始终位于第二行</p><p>2.add<br>add用于将value存储在指定的key中，如果add的key已经存在，则不会更新数据，与之前的值仍然保持相同，会得到NOT_STORED的响应，但是过期的key会更新。<br>语法格式如下：</p><pre><code>add key flags exptime bytes [noreply]value</code></pre><p>3.replace<br>replace用于替换已经存在的key的value，如果可以不存在，则替换失败，并且得到NOT_STORED的响应<br>语法格式如下：</p><pre><code>replace key flags exptime bytes [noreply]value</code></pre><p>4.append<br>append用于向已经存在key的value后面追加数据<br>语法格式如下：</p><pre><code>append key flags exptime bytes [noreply]value</code></pre><p>5.prepend<br>prepend命令用于向已经存在key的value前面追加数据<br>语法格式如下：</p><pre><code>prepend key flags exptime bytes [noreply]value</code></pre><p>6.cas<br>cas用于执行一个“检查并设置”的操作，它仅在当前客户端最后一次取值后，该key对应的值没有被其他客户端修改的情况下才能够将值写入。检查是通过cas_token参数进行的，这个参数是memcached指定给已经存在的元素的一个唯一的64位值。<br>语法格式如下：</p><pre><code>cas key flags exptime bytes unique_cas_token [noreply]value</code></pre><p>unique_cas_token是通过gets命令获取的一个唯一的64位值</p><h2 id="查找命令"><a href="#查找命令" class="headerlink" title="查找命令"></a>查找命令</h2><p>1.get<br>get用于获取存储在key中的value，如果key不存在，则返回空。若获取多个key的value，则使用空格将其隔开即可。<br>语法格式如下：</p><pre><code>get keyget key1 key2 key3</code></pre><p>2.gets<br>gets用于获取CAS令牌存的value,如果key不存在，则返回空。若获取多个key的value，则使用空格将其隔开即可。<br>语法格式如下：</p><pre><code>gets keygets key1 key2 key3</code></pre><p>3.delete<br>delete命令用于删除已经存在的key。<br>语法格式如下：</p><pre><code>delete key [noreply]</code></pre><p>4.incr/decr<br>incr和decr用于对已经存在的key的数字进行自增或自减操作。但是惭怍的数据必须是十进制的32位无符号整数，若key不存在，返回NOT_FOUND，若键的值不为数字，则返回CLIENT_ERROR，其他错误返回ERROR。<br>语法格式如下：</p><pre><code>incr key increment_values [noreply]decr key decrement_values [noreply]</code></pre><p>increment_values为增加的数值<br>decrement_values为减少的数值</p><p>5.flush_all<br>flush_all用于清理缓存中的所有的键值对，该命令提供了一个可选参数time，用于在制定的时间后执行清理缓存操作。<br>语法格式如下：</p><pre><code>flush_all [time] [noreply]</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;ubuntu16-0-4下memcached的安装&quot;&gt;&lt;a href=&quot;#ubuntu16-0-4下memcached的安装&quot; class=&quot;headerlink&quot; title=&quot;ubuntu16.0.4下memcached的安装&quot;&gt;&lt;/a&gt;ubuntu16.0.4下memcached的安装&lt;/h1&gt;
    
    </summary>
    
      <category term="大数据相关" scheme="http://moyingyao.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="memcached" scheme="http://moyingyao.github.io/tags/memcached/"/>
    
  </entry>
  
  <entry>
    <title>redis安装及简单命令</title>
    <link href="http://moyingyao.github.io/2018/05/25/redis%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4/"/>
    <id>http://moyingyao.github.io/2018/05/25/redis安装及简单命令/</id>
    <published>2018-05-25T08:45:50.000Z</published>
    <updated>2018-05-27T14:03:48.818Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis：REmote-DIctionary-Server"><a href="#Redis：REmote-DIctionary-Server" class="headerlink" title="Redis：REmote DIctionary Server"></a>Redis：REmote DIctionary Server</h1><a id="more"></a><h2 id="Redis-远程字典服务器"><a href="#Redis-远程字典服务器" class="headerlink" title="Redis(远程字典服务器)"></a>Redis(远程字典服务器)</h2><p>是完全开源免费的，用C语言编写，是一个高性能的（key/value）分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSQL数据库之一，也被人们称之为结构数据服务器。</p><h2 id="Redis逐步取代memcached的原因"><a href="#Redis逐步取代memcached的原因" class="headerlink" title="Redis逐步取代memcached的原因"></a>Redis逐步取代memcached的原因</h2><p>1.redis支持数据持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用<br>2.redis不仅仅直迟简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储<br>3.redis支持数据的备份，即master-slave魔术的数据备份</p><h2 id="Redis能做什么？"><a href="#Redis能做什么？" class="headerlink" title="Redis能做什么？"></a>Redis能做什么？</h2><p>1.内存存储和持久化：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务<br>2.取最新N个数据的操作，如：可以将最新的10条评论的ID放在redis的List集合里面<br>3.模拟类似于HttpSession这种需要设定过期时间的功能<br>4.发布、订阅消息系统<br>5.定时器、计数器</p><h2 id="与memcached区别"><a href="#与memcached区别" class="headerlink" title="与memcached区别"></a>与memcached区别</h2><p>都是key-value存储<br>memcached一旦服务关闭，数据会全部没有<br>redis服务关闭重启后数据还在</p><h1 id="安装Redis"><a href="#安装Redis" class="headerlink" title="安装Redis"></a>安装Redis</h1><p>我们的环境：<br>VMware Workplace<br>CentOS-6.5<br>redis-4.0.9<br>下载地址： Http://redis.io<br>将下载好的redis-4.0.9放入虚拟机中，并解压</p><pre><code>tar -zxvf redis-4.9.0.tar.gz</code></pre><p>redis内包含的文件<br><img src="https://i.imgur.com/inuGfQx.png" alt="">输入命令</p><pre><code>make</code></pre><p>运行运行makefile文件，要有GCC，没有则会报错。<br>安装gcc：</p><pre><code>yum install gcc-c++</code></pre><p>安装完成之后要进行二次make，但是之前要将上一次make不成功的残余文件清理，之后再make</p><pre><code>make discleanmake</code></pre><p>make完成后，执行</p><pre><code>make install</code></pre><p>出现下图所示即安装成功<br><img src="https://i.imgur.com/pbUT2FT.png" alt=""></p><h1 id="配置redis-conf"><a href="#配置redis-conf" class="headerlink" title="配置redis.conf"></a>配置redis.conf</h1><p>进入redis-4.0.9,将redis.conf拷贝一份，在拷贝后的上面进行修改<br>将redis.conf拷贝至myredis文件夹下</p><pre><code>vim redis.conf</code></pre><p><img src="https://i.imgur.com/ThxbeJV.png" alt="">将no修改为yes</p><h1 id="启动redis服务"><a href="#启动redis服务" class="headerlink" title="启动redis服务"></a>启动redis服务</h1><pre><code>cd /usr/local/bin</code></pre><p><img src="https://i.imgur.com/kWyradG.png" alt=""></p><pre><code>redis-server /home/myy/hadoop/myredis/redis.config</code></pre><p><img src="https://i.imgur.com/yJIzrIU.png" alt=""></p><h1 id="进入客户端"><a href="#进入客户端" class="headerlink" title="进入客户端"></a>进入客户端</h1><p>客户端默认端口为6379<br><img src="https://i.imgur.com/7tzwWOB.png" alt="">判断是否与服务端连接成功<img src="https://i.imgur.com/w0CV6tg.png" alt="">查看服务状态<img src="https://i.imgur.com/bli2295.png" alt="">关闭连接<img src="https://i.imgur.com/CX3oEJZ.png" alt="">关闭后查看服务就没有了<img src="https://i.imgur.com/IiXkIPf.png" alt=""></p><h1 id="基础了解"><a href="#基础了解" class="headerlink" title="基础了解"></a>基础了解</h1><h2 id="默认库"><a href="#默认库" class="headerlink" title="默认库"></a>默认库</h2><p>Redis默认有16个库，进入时默认在0号库，角标从0开始，某些任务找一号库，某些找二号库，任务逻辑更清晰redis.conf中有说明<img src="https://i.imgur.com/BU29JJY.png" alt="">转换库的命令，eg：切换为8号库<img src="https://i.imgur.com/J2FGtCY.png" alt=""></p><h2 id="flushdb和flushall的区别"><a href="#flushdb和flushall的区别" class="headerlink" title="flushdb和flushall的区别"></a>flushdb和flushall的区别</h2><p>flushdb是删除当前库，flushall是删除全部库</p><h2 id="Benchmark查看本机状态"><a href="#Benchmark查看本机状态" class="headerlink" title="Benchmark查看本机状态"></a>Benchmark查看本机状态</h2><p><img src="https://i.imgur.com/Z2Q0Fv3.png" alt=""><img src="https://i.imgur.com/7z1VOWO.png" alt=""><img src="https://i.imgur.com/i9NWdjz.png" alt=""><img src="https://i.imgur.com/LmtfECg.png" alt=""><img src="https://i.imgur.com/MXCvvnS.png" alt=""></p><h1 id="常用五大数据类型"><a href="#常用五大数据类型" class="headerlink" title="常用五大数据类型"></a>常用五大数据类型</h1><p>1.string字符串<br>String是redis最基本的类型，可以理解为与memcached一摸一样的类型，一个key对应一个value。<br>String类型是二进制安全的，即redis的string可以包含任何数据，比如jpg图片或者序列化对象<br>string是redis最基本的数据类型，一个redis中字符串最多可以是512M</p><p>2.hash哈希<br>redis hash是一个键值对集合，是一个string类型的filed和value的映射表，适合用于存储对象。<br>类似java中的Map&lt;String,Object&gt;</p><p>3.list列表<br>列表是简单的字符串列表，按照插入顺利排序。可以添加一个元素到列表的头部（左边）或者尾部（右边），它的底层实际是个链表</p><p>4.set集合<br>set是string类型的无序集合。是通过HashTable实现的。</p><p>5.Zset有序集合<br>Zset（sorted set）<br>zset和set一样也是string类型元素的集合，且不允许重复的成员。<br>不同的是每个元素都会关联一个double类型的分数。<br>redis正是通过分数来为集合中的成员进行从小到大的排序。zset的承宣是唯一的，但分数（score）是可以重复的。</p><h1 id="常用关键字"><a href="#常用关键字" class="headerlink" title="常用关键字"></a>常用关键字</h1><h2 id="set-get-exists-keys-move-mset-mget"><a href="#set-get-exists-keys-move-mset-mget" class="headerlink" title="set/get/exists/keys/move/mset/mget"></a>set/get/exists/keys/move/mset/mget</h2><p>set设置键值，也可以覆盖原来的值<br>get获取对应键的值<br>exists查看某个key是否存在<br>move移动到别的库内<br>mset/mget批量设置/获取键值</p><p><img src="https://i.imgur.com/iM55rsZ.png" alt=""><img src="https://i.imgur.com/AiFg5Jl.png" alt=""><img src="https://i.imgur.com/L0raU11.png" alt=""><img src="https://i.imgur.com/6aAYxKL.png" alt=""></p><h2 id="expire-ttl-setex"><a href="#expire-ttl-setex" class="headerlink" title="expire/ttl/setex"></a>expire/ttl/setex</h2><p>expire设置秒数，过期后自动消失<br>ttl 查看某个key还有多久时间<br>setex设置值时同时设置时间<img src="https://i.imgur.com/qAMGzHT.png" alt=""><img src="https://i.imgur.com/AAWcCWc.png" alt=""></p><h2 id="append-strlen-getrange-setrange-incr-decr-incrby-decrby"><a href="#append-strlen-getrange-setrange-incr-decr-incrby-decrby" class="headerlink" title="append/strlen/getrange/setrange/incr/decr/incrby/decrby"></a>append/strlen/getrange/setrange/incr/decr/incrby/decrby</h2><p>append补充字符串<br>strlen字符串的长度<br>getrange获取指定区域范围内的值，0到-1表示全部<br>setrange设置指定区域范围内的值<br>incr递增加1<br>decr递减少1<br>incrby   decrby自定义数量<br>string类型此命令不可用<br><img src="https://i.imgur.com/UjpKfJa.png" alt=""><img src="https://i.imgur.com/0Tqgcyz.png" alt=""><img src="https://i.imgur.com/Erl8ku1.png" alt=""></p><h2 id="lpush-lrange-lpop-rpop-lidex-llen"><a href="#lpush-lrange-lpop-rpop-lidex-llen" class="headerlink" title="lpush/lrange/lpop/rpop/lidex/llen"></a>lpush/lrange/lpop/rpop/lidex/llen</h2><p>lpush和rpush查看后顺序不同<br>lrange查看list<br>lpop栈顶出去<br>rpop栈底出去<br>lidex索引<br>llen查看list长度<br><img src="https://i.imgur.com/SmiHEoI.png" alt=""><img src="https://i.imgur.com/QSJZtGe.png" alt=""><img src="https://i.imgur.com/13DBD6n.png" alt=""></p><h2 id="lren-ltrim-rpoplpush-lset-linsert"><a href="#lren-ltrim-rpoplpush-lset-linsert" class="headerlink" title="lren/ltrim/rpoplpush/lset/linsert"></a>lren/ltrim/rpoplpush/lset/linsert</h2><p>lrem删除n和value<br>ltrim截取指定范围内的值再赋值给list<br>rpoplpush将list01栈底给list02栈顶<br>lset替换某位置的值<br>linsert某值之前或之后插入某值<br><img src="https://i.imgur.com/hxDg2SU.png" alt=""><img src="https://i.imgur.com/mXG2x8p.png" alt=""><img src="https://i.imgur.com/RF5E1Vy.png" alt=""><img src="https://i.imgur.com/zguZHDx.png" alt=""><img src="https://i.imgur.com/nO5lZGc.png" alt=""></p><h2 id="sadd-smembers-sismember-scard-srem-srandmember"><a href="#sadd-smembers-sismember-scard-srem-srandmember" class="headerlink" title="sadd/smembers/sismember/scard/srem/srandmember"></a>sadd/smembers/sismember/scard/srem/srandmember</h2><p>sadd设置set集合（重复自动留一个）<br>smembers查看set集合<br>sismember查看set内是否有某值<br>scard获取集合内元素个数<br>srem删除集合内某值<br>srandmember集合中随机出几个数<br><img src="https://i.imgur.com/toMNESc.png" alt=""><img src="https://i.imgur.com/NeBJIHu.png" alt=""><img src="https://i.imgur.com/QSZbjLr.png" alt=""><img src="https://i.imgur.com/GZ37ulu.png" alt=""></p><h2 id="spop-smove-sdiff-sinter-sunion"><a href="#spop-smove-sdiff-sinter-sunion" class="headerlink" title="spop/smove/sdiff/sinter/sunion"></a>spop/smove/sdiff/sinter/sunion</h2><p>spop随机出栈<br>smove将一set中某一值<br>赋给另一set<br>sdiff取两集合的差集：在第一个中而不在第二个中<br>sinter取两集合的交集<br>sunion取两集合的并集<br><img src="https://i.imgur.com/XyQXNW7.png" alt=""><img src="https://i.imgur.com/dRWsJJV.png" alt=""><img src="https://i.imgur.com/u6TdF2U.png" alt=""></p><h2 id="zrange-zrevrange-zcount"><a href="#zrange-zrevrange-zcount" class="headerlink" title="zrange/zrevrange/zcount"></a>zrange/zrevrange/zcount</h2><p>zrange同list相同<br>zrevrange从高到低排序<br>zincrby修改某个值的分数<br>zcount返回指定分数范围内值的个数<img src="https://i.imgur.com/q7suFVE.png" alt=""><img src="https://i.imgur.com/EqTjeHX.png" alt=""><img src="https://i.imgur.com/wQCzN1l.png" alt=""><img src="https://i.imgur.com/10VijR6.png" alt=""></p><h2 id="hash相关的关键字"><a href="#hash相关的关键字" class="headerlink" title="hash相关的关键字"></a>hash相关的关键字</h2><p>kv模式不变，但v是一个键值对<br><img src="https://i.imgur.com/GGPPbYV.png" alt=""><img src="https://i.imgur.com/JnBAXGt.png" alt=""><img src="https://i.imgur.com/EUYBanW.png" alt=""><img src="https://i.imgur.com/KUlb3nd.png" alt=""><img src="https://i.imgur.com/jO0YeHh.png" alt=""><img src="https://i.imgur.com/JEnzQND.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Redis：REmote-DIctionary-Server&quot;&gt;&lt;a href=&quot;#Redis：REmote-DIctionary-Server&quot; class=&quot;headerlink&quot; title=&quot;Redis：REmote DIctionary Server&quot;&gt;&lt;/a&gt;Redis：REmote DIctionary Server&lt;/h1&gt;
    
    </summary>
    
      <category term="大数据相关" scheme="http://moyingyao.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="redis" scheme="http://moyingyao.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>hadoop 分布式搭建</title>
    <link href="http://moyingyao.github.io/2018/05/25/hadoop-%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA/"/>
    <id>http://moyingyao.github.io/2018/05/25/hadoop-分布式搭建/</id>
    <published>2018-05-25T07:58:55.000Z</published>
    <updated>2018-05-25T08:37:47.895Z</updated>
    
    <content type="html"><![CDATA[<p>linux环境下搭建hadoop集群</p><h1 id="准备工具"><a href="#准备工具" class="headerlink" title="准备工具"></a>准备工具</h1><p>VMware-workstation-10.0.1注册机<br>CentOS-6.5-x86_64-bin-DVD1<br>jdk-7u79-linux-x64<br>hadoop-2.6.4.tar<br><a id="more"></a><br><img src="https://i.imgur.com/vrtN7JU.png" alt=""></p><h1 id="新建虚拟机"><a href="#新建虚拟机" class="headerlink" title="新建虚拟机"></a>新建虚拟机</h1><p>解压VMware-workstation-10.0.1注册机,打开VMware Workstation主页,点击新建虚拟机,选择典型,如下:<br><img src="https://i.imgur.com/Wbzensp.png" alt=""><br>点击下一步,选择安装程序光盘映像文件,浏览找到你下载CentOS-6.5-x86_64-bin-DVD1的压缩包文件,如下:<br><img src="https://i.imgur.com/IzWxBjV.png" alt=""><br>继续点击下一步,填写用户名和密码(尽量简单),填好后点击下一步,为即将创建的虚拟机命名并选择安装路径(最好不要安装在C盘),如下所示:<br><img src="https://i.imgur.com/hjdvvqZ.png" alt=""><br>继续点击下一步至如下界面:<br><img src="https://i.imgur.com/chMAScN.png" alt=""><br>点击自定义硬件可以修改虚拟机的各项参数,如果电脑内存小于等于4GB,需要将内存改至512MB,否则严重卡顿。修改完成后点击完成，虚拟机就创建成功，打开后界面如下：<br><img src="https://i.imgur.com/RlJpVk3.png" alt=""><br>若要批量创建虚拟机，可以在创建好的虚拟机的基础上进行克隆操作，<br><img src="https://i.imgur.com/lbyJLai.png" alt=""></p><h1 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h1><p>打开一个虚拟机，右键单击桌面选择Open in Terminal，进入编辑界面：</p><h2 id="假设用户名为wxx"><a href="#假设用户名为wxx" class="headerlink" title="假设用户名为wxx"></a>假设用户名为wxx</h2><h3 id="获取root权限"><a href="#获取root权限" class="headerlink" title="获取root权限"></a>获取root权限</h3><pre><code>su  cd /etcvi sudoers</code></pre><p>i 进入编辑状态，在</p><pre><code>root ALL=(ALL)    </code></pre><p>ALL的下一行编辑</p><pre><code>wxx  ALL=(ALL) ALL</code></pre><p>按ESC键，退出编辑格式<br>按Shift + :<br>输入wq!保存并退出</p><h3 id="创建hadoop文件夹"><a href="#创建hadoop文件夹" class="headerlink" title="创建hadoop文件夹"></a>创建hadoop文件夹</h3><pre><code>cdmkdir  hadoop</code></pre><p>将jdk-7u79-linux-x64安装包复制到hadoop文件目录下（与windows环境下类似）。</p><h3 id="解压jdk-7u79-linux-x64-gz文件"><a href="#解压jdk-7u79-linux-x64-gz文件" class="headerlink" title="解压jdk-7u79-linux-x64.gz文件"></a>解压jdk-7u79-linux-x64.gz文件</h3><pre><code>cdcd hadooptar-zxvf jdk-7u79-linux-x64.gz</code></pre><h3 id="设置jdk环境变量"><a href="#设置jdk环境变量" class="headerlink" title="设置jdk环境变量"></a>设置jdk环境变量</h3><pre><code>cdcd  hadoopsugedit /etc/profile</code></pre><p>进入后在最后一行添加以下指令：<br>    export JAVA_HOME=/home/by/hadoop/jdk1.8.0_11<br>    export PATH=$JAVA_HOME/bin:$PATH<br>    export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>点击保存后关闭，输入以下指令使jdk生效：<br>    source /etc/profile</p><h3 id="检查jdk是否安装成功"><a href="#检查jdk是否安装成功" class="headerlink" title="检查jdk是否安装成功"></a>检查jdk是否安装成功</h3><pre><code>java -version</code></pre><p>成功后显示如下信息：<br>    java version “1.7.0_79”<br>    Java(TM) SE Runtime Environment (build 1.7.0_79-b15)<br>    Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</p><h1 id="创建集群"><a href="#创建集群" class="headerlink" title="创建集群"></a>创建集群</h1><h2 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h2><p>将已经安装好jdk的虚拟机克隆两个，创建三个虚拟机的集群。</p><h2 id="修改hostname"><a href="#修改hostname" class="headerlink" title="修改hostname"></a>修改hostname</h2><pre><code>suvi  /etc/sysconfig/network</code></pre><p>将三个虚拟机分别命名master、slave1、slave2<br>如图：<br><img src="https://i.imgur.com/wUQ1xjq.png" alt=""><br>完成后重启虚拟机reboot</p><h2 id="将三个虚拟机的ip地址相互连接"><a href="#将三个虚拟机的ip地址相互连接" class="headerlink" title="将三个虚拟机的ip地址相互连接"></a>将三个虚拟机的ip地址相互连接</h2><p>首先必须确保虚拟机联网，如果NET模式连不上网，则选中桥接模式。<br>网络通畅后执行以下操作:<br>1.查看三台虚拟机IP,分别对三个虚拟机执行指令ifconfig，查看各虚拟机ip地址</p><p>2.在master中执行以下指令</p><pre><code>sucd/etcgedit /etc/hosts 192.168.142.142 192.168.142.143</code></pre><p>进入编辑界面后按“IP地址   hostname”填写信息，如图：<br><img src="https://i.imgur.com/O1rxMcZ.png" alt=""><br>填写完后按Save按钮，关闭编辑页。</p><p>3.将配置好的文件复制到slave1、slave2中,在master中执行以下指令：<br>    scp /etc/hosts root@slave1:/etc/<br>    scp /etc/hosts root@slave2:/etc/    </p><p>4.检查各虚拟机是否互联,在master中执行以下指令：<br>    ping slave1<br>    ping slave2<br>连通即完成</p><h2 id="配置SSH无密钥登录"><a href="#配置SSH无密钥登录" class="headerlink" title="配置SSH无密钥登录"></a>配置SSH无密钥登录</h2><p>1.关闭防火墙,对每个虚拟机进行如下操作：</p><pre><code>suchkconfig iptables off</code></pre><p>执行后重启虚拟机： </p><pre><code>reboot</code></pre><p>2.关闭防火墙后在master下执行以下指令：<br>    cd<br>    ssh-keygen –t rsa<br>    cd  .ssh<br>    cat  id_rsa.pub  &gt;&gt;  authorized_keys<br>    chmod  600  authorized_keys<br>    scp  authorized_keys  wxx@slave1:~/.ssh/<br>    scp  authorized_keys  wxx@slave2:~/.ssh/</p><p>3.检查无密钥登录是否成功<br>    ssh slave1<br>    ssh slave2<br>    ssh  master<br>成功后显示如下：<br><img src="https://i.imgur.com/I25emLH.png" alt=""></p><h2 id="安装并配置hadoop-2-6-4-在master中"><a href="#安装并配置hadoop-2-6-4-在master中" class="headerlink" title="安装并配置hadoop-2.6.4(在master中)"></a>安装并配置hadoop-2.6.4(在master中)</h2><p>1.将hadoop-2.6.4.tar.gz安装包复制到hadoop文件目录下（与windows环境下类似）。</p><p>2.解压hadoop-2.6.4.tar.gz</p><pre><code>cdcd hadooptar -zxvf hadoop-2.6.4.tar.gz</code></pre><p>3.配置hadoop-2.6.4的各项文件</p><pre><code>cdcd hadoop/hadoop-2.7.4cd etc/hadoopgedit hadoop-env.sh</code></pre><p>在最后一行添加:</p><pre><code>export JAVA_HOME=/home/by/hadoop/ jdk1.8.0_11</code></pre><h3 id="编辑core-site-xml"><a href="#编辑core-site-xml" class="headerlink" title="编辑core-site.xml"></a>编辑core-site.xml</h3><pre><code>gedit core-site.xml</code></pre><p>添加代码：</p><pre><code>&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/home/by/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;ds.default.name&lt;/name&gt;&lt;value&gt;hdfs://master:54310&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;</code></pre><h3 id="编辑hdfs-site-xml"><a href="#编辑hdfs-site-xml" class="headerlink" title="编辑hdfs-site.xml"></a>编辑hdfs-site.xml</h3><pre><code>gedit hdfs-site.xml</code></pre><p>添加代码：</p><pre><code>&lt;property&gt;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;&lt;value&gt;file:/home/by/hadoop/dfs/name&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;&lt;value&gt;file:/home/by/hadoop/dfs/data&lt;/value&gt;&lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;2&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="编辑mapred-site-xml"><a href="#编辑mapred-site-xml" class="headerlink" title="编辑mapred-site.xml"></a>编辑mapred-site.xml</h3><pre><code>gedit mapred-site.xml</code></pre><p>注意：必须先复制mapred-site.xml.template文件更名为mapred-site.xml<br>添加代码：</p><pre><code>&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;&lt;value&gt;master:10020&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;&lt;value&gt;master:19888&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="编辑yarn-site-xml"><a href="#编辑yarn-site-xml" class="headerlink" title="编辑yarn-site.xml"></a>编辑yarn-site.xml</h3><pre><code>gedit  yarn-site.xml</code></pre><p>添加代码：</p><pre><code>&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;&lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;&lt;value&gt;master:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;&lt;value&gt;master:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;&lt;value&gt;master:8031&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;&lt;value&gt;master:8033&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;&lt;value&gt;master:8088&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="编辑master"><a href="#编辑master" class="headerlink" title="编辑master"></a>编辑master</h3><pre><code>gedit master</code></pre><p>添加代码：</p><pre><code>master</code></pre><h3 id="编辑slaves"><a href="#编辑slaves" class="headerlink" title="编辑slaves"></a>编辑slaves</h3><pre><code>gedit slaves</code></pre><p>添加代码：</p><pre><code>masterslave1slave2</code></pre><p>4.将配置好的文件复制到slave1、slave2中</p><pre><code>cd cd hadoopscp -r hadoop-2.7.4 slave1:~/hadoopscp -r hadoop-2.7.4 slave2:~/hadoop</code></pre><p>5.启动集群</p><pre><code>cdcd  hadoop/hadoop-2.7.4bin/hdfs namenode  -formatsbin/start-dfs.shsbin/start-yarn.shsbin/hadoop-daemon.sh  start  secondarynamenode</code></pre><p>6.检查集群情况</p><pre><code>jps</code></pre><p>三台虚拟机如下所示：<br><img src="https://i.imgur.com/Y1KfeJY.png" alt=""><br><img src="https://i.imgur.com/VlP3QMy.png" alt=""><br><img src="https://i.imgur.com/7Nsazie.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;linux环境下搭建hadoop集群&lt;/p&gt;
&lt;h1 id=&quot;准备工具&quot;&gt;&lt;a href=&quot;#准备工具&quot; class=&quot;headerlink&quot; title=&quot;准备工具&quot;&gt;&lt;/a&gt;准备工具&lt;/h1&gt;&lt;p&gt;VMware-workstation-10.0.1注册机&lt;br&gt;CentOS-6.5-x86_64-bin-DVD1&lt;br&gt;jdk-7u79-linux-x64&lt;br&gt;hadoop-2.6.4.tar&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="大数据相关" scheme="http://moyingyao.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="hadoop" scheme="http://moyingyao.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>LaTeX入门</title>
    <link href="http://moyingyao.github.io/2018/05/25/LaTeX%E5%85%A5%E9%97%A8/"/>
    <id>http://moyingyao.github.io/2018/05/25/LaTeX入门/</id>
    <published>2018-05-25T07:04:26.000Z</published>
    <updated>2018-05-25T07:52:04.485Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h1><p>打开WinEdt，建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8。<br><a id="more"></a></p><pre><code>\documentclass{article}  \begin{document}  hello, world  \end{document} </code></pre><p>然后在WinEdt的工具栏中找到编译按钮（在垃圾桶和字母B中间），在下拉菜单中选择XeTeX，并点击编译。<br>如果顺利的话，就可以顺利生成出第一个pdf文件，点击工具栏中的放大镜按钮就可以快速打开生成的pdf文件。 </p><h1 id="标题、作者、章节和段落"><a href="#标题、作者、章节和段落" class="headerlink" title="标题、作者、章节和段落"></a>标题、作者、章节和段落</h1><p>建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8，编译并观察现象。</p><pre><code>\documentclass{article}  \author{My Name}  \title{The Title}  \begin{document}  \maketitle  hello, world % This is comment  \end{document} </code></pre><p>效果图如下：<br><img src="https://i.imgur.com/KPP0wzq.png" alt=""> </p><h1 id="加入目录"><a href="#加入目录" class="headerlink" title="加入目录"></a>加入目录</h1><p>建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8，编译并观察现象。</p><pre><code>\documentclass{article}  \begin{document}  \tableofcontents  \section{Hello China} China is in East Asia.  \subsection{Hello Beijing} Beijing is the capital of China.  \subsubsection{Hello Dongcheng District}  \paragraph{Hello Tian&apos;anmen Square}is in the center of Beijing  \subparagraph{Hello Chairman Mao} is in the center of Tian&apos;anmen Square  \end{document} </code></pre><p>效果图如下：<br><img src="https://i.imgur.com/5KAaLd6.png" alt=""> </p><h1 id="段落和换行"><a href="#段落和换行" class="headerlink" title="段落和换行"></a>段落和换行</h1><pre><code>\documentclass{article}  \begin{document}  Beijing is  the capital  of China.  New York is  the capital  of America.  Amsterdam is \\ the capital \\  of Netherlands.  \end{document} </code></pre><p>效果图如下：<br><img src="https://i.imgur.com/Rpk6Hh2.png" alt=""></p><h1 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h1><pre><code>\documentclass{article}  \usepackage{amsmath}  \usepackage{amssymb}  \begin{document}  The Newton&apos;s second law is F=ma.  The Newton&apos;s second law is $F=ma$.  The Newton&apos;s second law is  F=maThe Newton&apos;s second law is  F=maGreek Letters $\eta$ and $\mu$  Fraction $\frac{a}{b}$  Power $a^b$  Subscript $a_b$  Derivate $\frac{\partial y}{\partial t} $  Vector $\vec{n}$  Bold $\mathbf{n}$  To time differential $\dot{F}$  Matrix (lcr here means left, center or right for each column)  \[  \left[  \begin{array}{lcr}  a1 &amp; b22 &amp; c333 \\  d444 &amp; e555555 &amp; f6  \end{array}  \right]  \]  Equations(here \&amp; is the symbol for aligning different rows)  \begin{align}  a+b&amp;=c\\  d&amp;=e+f+g  \end{align}  \[  \left\{  \begin{aligned}  &amp;a+b=c\\  &amp;d=e+f+g  \end{aligned}  \right.  \]  \end{document} </code></pre><p>效果图如下：<br><img src="https://i.imgur.com/JCSYPxO.png" alt=""></p><h1 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h1><p>先搜索到一个将图片转成eps文件的软件，很容易找的，然后将图片保存为一个名字如figure1.eps。<br>建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8，放在和图片文件同一个文件夹里，编译并观察现象。</p><pre><code>\documentclass{article}  \usepackage{graphicx}  \begin{document}  \includegraphics[width=4.00in,height=3.00in]{figure1.eps}  \end{document}</code></pre><h1 id="简单表格"><a href="#简单表格" class="headerlink" title="简单表格"></a>简单表格</h1><pre><code>\documentclass{article}\begin{document}\begin{tabular}{|c|c|}a &amp; b \\c &amp; d\\\end{tabular}\begin{tabular}{|c|c|}\hlinea &amp; b \\\hlinec &amp; d\\\hline\end{tabular}\begin{center}\begin{tabular}{|c|c|}\hlinea &amp; b \\ \hlinec &amp; d\\\hline\end{tabular}\end{center}\end{document}</code></pre><p>效果图如下：<br><img src="https://i.imgur.com/JoYKa5s.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hello-World&quot;&gt;&lt;a href=&quot;#Hello-World&quot; class=&quot;headerlink&quot; title=&quot;Hello World&quot;&gt;&lt;/a&gt;Hello World&lt;/h1&gt;&lt;p&gt;打开WinEdt，建立一个新文档，将以下内容复制进入文档中，保存，保存类型选择为UTF-8。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="文档编写" scheme="http://moyingyao.github.io/categories/%E6%96%87%E6%A1%A3%E7%BC%96%E5%86%99/"/>
    
    
      <category term="LaTeX" scheme="http://moyingyao.github.io/tags/LaTeX/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战--决策树</title>
    <link href="http://moyingyao.github.io/2018/05/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>http://moyingyao.github.io/2018/05/25/机器学习实战-决策树/</id>
    <published>2018-05-25T02:32:28.000Z</published>
    <updated>2018-05-25T03:05:40.151Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特诊数据<br>缺点：可能会产生过度匹配问题<br>使用数据类型：数值型和标称型<br>专家系统中，经常使用决策树<br><a id="more"></a></p><h1 id="trees-py"><a href="#trees-py" class="headerlink" title="trees.py"></a>trees.py</h1><pre><code>from math import log    import operator</code></pre><h2 id="createDataSet"><a href="#createDataSet" class="headerlink" title="createDataSet()"></a>createDataSet()</h2><p>创建数据集</p><pre><code>def createDataSet():    # 数据集中两个特征&apos;no surfacing&apos;,&apos;flippers&apos;, 数据的两个类标签&apos;yes&apos;,&apos;no    #dataSet是个list    dataSet = [[1, 1, &apos;yes&apos;],                 [1, 1, &apos;yes&apos;],                 [1, 0, &apos;no&apos;],                 [0, 1, &apos;no&apos;],                 [0, 1, &apos;no&apos;]]    labels = [&apos;no surfacing&apos;,&apos;flippers&apos;]    return dataSet, labels</code></pre><h2 id="calcShannonEnt-dataSet"><a href="#calcShannonEnt-dataSet" class="headerlink" title="calcShannonEnt(dataSet)"></a>calcShannonEnt(dataSet)</h2><p>计算给定数据集的熵</p><pre><code>def calcShannonEnt(dataSet):    numEntries = len(dataSet)   #计算数据集中实例的总数    labelCounts = {}            #创建空字典    for featVec in dataSet:     #提取数据集每一行的特征向量        currentLabel = featVec[-1]  #获取特征向量最后一列的标签        # 检测字典的关键字key中是否存在该标签，如果不存在keys()关键字，将当前标签/0键值对存入字典中,并赋值为0        #print(labelCounts.keys())        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0        #print(labelCounts)        labelCounts[currentLabel] += 1  #否则将当前标签对应的键值加1        #print(&quot;%s=&quot;%currentLabel,labelCounts[currentLabel])    shannonEnt = 0.0    #初始化熵为0    for key in labelCounts:        prob = float(labelCounts[key])/numEntries   #计算各值出现的频率        shannonEnt -= prob * log(prob,2)    #以2为底求对数再乘以出现的频率，即信息期望值        #print(&quot;%s=&quot;%labelCounts[key],shannonEnt)    return shannonEnt</code></pre><h2 id="splitDataSet-dataSet-axis-value"><a href="#splitDataSet-dataSet-axis-value" class="headerlink" title="splitDataSet(dataSet, axis, value)"></a>splitDataSet(dataSet, axis, value)</h2><p>按照给定特征划分数据集<br>得到熵之后，还需划分数据集，以便判断当前是否正确地划分了数据集，三个输入参数分别为：带划分的数据集，划分数据集的特征，需要返回的特征得值，挑选出dataSet中axis位置值为value的剩余部分。</p><pre><code>def splitDataSet(dataSet, axis, value):    retDataSet = []    for featVec in dataSet:        if featVec[axis] == value:  #筛选出dataSet中axis位置值为value            #列表的索引中冒号的作用，a[1: ]表示该列表中的第1个元素到最后一个元素，而a[ : n]表示从第0歌元素到第n个元素(不包括n)            reducedFeatVec = featVec[:axis] #取出特定位置前面部分并赋值给reducedFeatVec            #print(featVec[axis+1:])            #print(reducedFeatVec)            reducedFeatVec.extend(featVec[axis+1:])     #取出特定位置后面部分并赋值给reducedFeatVec            retDataSet.append(reducedFeatVec)            #print(retDataSet)    return retDataSet</code></pre><h2 id="chooseBestFeatureToSplit-dataSet"><a href="#chooseBestFeatureToSplit-dataSet" class="headerlink" title="chooseBestFeatureToSplit(dataSet)"></a>chooseBestFeatureToSplit(dataSet)</h2><p>选择最好的数据集划分方式<br>选取特征，划分数据集，计算得出最好的划分数据集的特征</p><pre><code>def chooseBestFeatureToSplit(dataSet):    numFeatures = len(dataSet[0]) - 1      #计算特征数量，即每一列表元素具有的列数，再减去最后一列为标签，故需减去1    baseEntropy = calcShannonEnt(dataSet)       #计算信息熵，此处值为0.9709505944546686，此值将与划分之后的数据集计算的信息熵进行比较    bestInfoGain = 0.0;bestFeature = -1    for i in range(numFeatures):        featList = [example[i] for example in dataSet]      #创建标签列表        #print(featList)        uniqueVals = set(featList)       #确定某一特征下所有可能的取值,set集合类型中的每个值互不相同        #print(uniqueVals)        newEntropy = 0.0        for value in uniqueVals:        #计算每种划分方式的信息熵            subDataSet = splitDataSet(dataSet, i, value)        #抽取该特征的每个取值下其他特征的值组成新的子数据集            prob = len(subDataSet)/float(len(dataSet))      #计算该特征下的每一个取值对应的概率（或者说所占的比重）            newEntropy += prob * calcShannonEnt(subDataSet)     #计算该特征下每一个取值的子数据集的信息熵，并求和        infoGain = baseEntropy - newEntropy     #计算每个特征的信息增益        #print(&quot;第%d个特征是的取值是%s，对应的信息增益值是%f&quot;%((i+1),uniqueVals,infoGain))        if (infoGain &gt; bestInfoGain):            bestInfoGain = infoGain            bestFeature = i            #print(&quot;第%d个特征的信息增益最大，所以选择它作为划分的依据，其特征的取值为%s,对应的信息增益值是%f&quot;%((i+1),uniqueVals,infoGain))    return bestFeature</code></pre><h2 id="majorityCnt-classList"><a href="#majorityCnt-classList" class="headerlink" title="majorityCnt(classList)"></a>majorityCnt(classList)</h2><p>递归构建决策树，返回出现次数最多的分类名称</p><pre><code>def majorityCnt(classList):    classCount={}    for vote in classList:        if vote not in classCount.keys(): classCount[vote] = 0        classCount[vote] += 1    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)    return sortedClassCount[0][0]</code></pre><h2 id="createTree-dataSet-labels"><a href="#createTree-dataSet-labels" class="headerlink" title="createTree(dataSet,labels)"></a>createTree(dataSet,labels)</h2><p>创建树,参数为数据集和标签列表</p><pre><code>def createTree(dataSet,labels):    classList = [example[-1] for example in dataSet]       #提取dataset中的最后一列——种类标签    #print(classList)    if classList.count(classList[0]) == len(classList):    #计算classlist[0]出现的次数,如果相等，说明都是属于一类，不用继续往下划分        return classList[0]     #递归结束的第一个条件是所有的类标签完全相同，则直接返回该类标签    #print(dataSet[0])    if len(dataSet[0]) == 1: #看还剩下多少个属性，如果只有一个属性，但是类别标签有多个，就直接用majoritycnt()进行整理，选取类别最多的作为返回值        return majorityCnt(classList)   #递归结束的第二个条件是使用完了所有的特征，仍然不能将数据集划分成仅包含唯一类别的分组，则返回出现次数最多的类别    bestFeat = chooseBestFeatureToSplit(dataSet)    #选取信息增益最大的特征作为下一次分类的依据    bestFeatLabel = labels[bestFeat]     #选取特征对应的标签    #print(bestFeatLabel)    myTree = {bestFeatLabel:{}}  #创建tree字典，下一个特征位于第二个大括号内，循环递归    del(labels[bestFeat])   #删除使用过的特征    featValues = [example[bestFeat] for example in dataSet]     #特征值对应的该栏数据    #print(featValues)    uniqueVals = set(featValues)    #找到featvalues所包含的所有元素，去重复    for value in uniqueVals:        subLabels = labels[:]        #将使用过的标签删除更新后，赋值给新的列表，进行迭代        #print(subLabels)        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat,value),subLabels) #循环递归生成树    return myTree                            </code></pre><h2 id="classify-inputTree-featLabels-testVec"><a href="#classify-inputTree-featLabels-testVec" class="headerlink" title="classify(inputTree,featLabels,testVec):"></a>classify(inputTree,featLabels,testVec):</h2><p>测试算法，使用决策树执行分类</p><pre><code>def classify(inputTree,featLabels,testVec):    firstStr = list(inputTree.keys())[0]    #找到树的第一个分类特征，或者说根节点&apos;no surfacing&apos;    #print(firstStr)    secondDict = inputTree[firstStr]    #从树中得到该分类特征的分支，有0和1    #print(secondDict)    featIndex = featLabels.index(firstStr)  #根据分类特征的索引找到对应的标称型数据值，&apos;no surfacing&apos;对应的索引为0    #print(featIndex)    key = testVec[featIndex]    valueOfFeat = secondDict[key]    if isinstance(valueOfFeat, dict):         classLabel = classify(valueOfFeat, featLabels, testVec)    else: classLabel = valueOfFeat    return classLabel</code></pre><h2 id="storeTree-inputTree-filename"><a href="#storeTree-inputTree-filename" class="headerlink" title="storeTree(inputTree,filename)"></a>storeTree(inputTree,filename)</h2><p>决策树的存储，使用pickle序列化对象，可在磁盘中保存对象。</p><pre><code>def storeTree(inputTree,filename):    import pickle    fw = open(filename,&apos;wb&apos;)    #二进制写入&apos;wb&apos;    pickle.dump(inputTree,fw)   #pickle的dump函数将决策树写入文件中    fw.close()def grabTree(filename):    import pickle    fr = open(filename,&apos;rb&apos;)    #对应于二进制方式写入数据，&apos;rb&apos;采用二进制形式读出数据    return pickle.load(fr)</code></pre><h1 id="trees-main-py"><a href="#trees-main-py" class="headerlink" title="trees_main.py"></a>trees_main.py</h1><pre><code>import treesfrom imp import reloadimport treePlotter</code></pre><h2 id="创建数据集"><a href="#创建数据集" class="headerlink" title="创建数据集"></a>创建数据集</h2><pre><code>myDat,labels=trees.createDataSet()#print(myDat)#print(labels)#print(trees.calcShannonEnt(myDat))</code></pre><h2 id="熵增大的原因"><a href="#熵增大的原因" class="headerlink" title="熵增大的原因"></a>熵增大的原因</h2><p>熵越高，混合的数据就越多，如果我们在数据集中添加更多的分类，会导致熵结果增大</p><pre><code>#myDat[1][-1]=&apos;maybe&apos;#更改list中某一元素的值（除yes和no外的值），即为添加更多的分类，中括号中为对应元素行列的位置#print(myDat)#print(trees.calcShannonEnt(myDat))  #分类变多，熵增大</code></pre><h2 id="append-和extend-两类方法的区别"><a href="#append-和extend-两类方法的区别" class="headerlink" title="append()和extend()两类方法的区别"></a>append()和extend()两类方法的区别</h2><pre><code>a=[1,2,3]b=[4,5,6]a.append(b)#print(a)#[1, 2, 3, [4, 5, 6]]a.extend(b)#print(a)#[1, 2, 3, [4, 5, 6], 4, 5, 6]</code></pre><h2 id="按照给定特征划分数据集"><a href="#按照给定特征划分数据集" class="headerlink" title="按照给定特征划分数据集"></a>按照给定特征划分数据集</h2><pre><code>#print(myDat)#print(trees.splitDataSet(myDat,0,1))#print(trees.splitDataSet(myDat,0,0))</code></pre><h2 id="选择最好的数据集划分方式"><a href="#选择最好的数据集划分方式" class="headerlink" title="选择最好的数据集划分方式"></a>选择最好的数据集划分方式</h2><pre><code>#print(myDat)#print(trees.chooseBestFeatureToSplit(myDat))</code></pre><h2 id="创建树-参数为数据集和标签列表"><a href="#创建树-参数为数据集和标签列表" class="headerlink" title="创建树,参数为数据集和标签列表"></a>创建树,参数为数据集和标签列表</h2><pre><code>myTree=trees.createTree(myDat,labels)#print(myTree)myDat,labels=trees.createDataSet()myTree1=treePlotter.retrieveTree(0)    #print(myTree1)#print(trees.classify(myTree1,labels,[1,0]))#print(trees.classify(myTree,labels,[1,1]))</code></pre><h2 id="决策树的存储"><a href="#决策树的存储" class="headerlink" title="决策树的存储"></a>决策树的存储</h2><pre><code>trees.storeTree(myTree,&apos;classifierStorage.txt&apos;)#print(trees.grabTree(&apos;classifierStorage.txt&apos;))</code></pre><h2 id="使用决策树预测隐形眼镜类型"><a href="#使用决策树预测隐形眼镜类型" class="headerlink" title="使用决策树预测隐形眼镜类型"></a>使用决策树预测隐形眼镜类型</h2><pre><code>fr=open(&apos;lenses.txt&apos;)lenses = [inst.strip().split(&apos;\t&apos;) for inst in fr.readlines()]  #将文本数据的每一个数据行按照tab键分割，并依次存入lenseslensesLabels = [&apos;age&apos;, &apos;prescript&apos;, &apos;astigmatic&apos;, &apos;tearRate&apos;]   # 创建并存入特征标签列表lensesTree = trees.createTree(lenses, lensesLabels)   # 根据继续文件得到的数据集和特征标签列表创建决策树print(lensesTree)treePlotter.createPlot(lensesTree)</code></pre><h1 id="treePlotter-py"><a href="#treePlotter-py" class="headerlink" title="treePlotter.py"></a>treePlotter.py</h1><p>python中使用Matplotlib注解绘制树形图</p><pre><code>import matplotlib.pyplot as plt</code></pre><h2 id="定义文本框和箭头格式"><a href="#定义文本框和箭头格式" class="headerlink" title="定义文本框和箭头格式"></a>定义文本框和箭头格式</h2><pre><code>decisionNode = dict(boxstyle=&quot;sawtooth&quot;, fc=&quot;0.8&quot;)  # boxstyle为文本框的类型，sawtooth是锯齿形，fc是边框线粗细,pad指的是外边框锯齿形（圆形等）的大小leafNode = dict(boxstyle=&quot;round4&quot;, fc=&quot;0.8&quot;)    #定义决策树的叶子结点的描述属性，round4表示圆形arrow_args = dict(arrowstyle=&quot;&lt;-&quot;)  #定义箭头属性</code></pre><h2 id="plotNode-nodeTxt-centerPt-parentPt-nodeType"><a href="#plotNode-nodeTxt-centerPt-parentPt-nodeType" class="headerlink" title="plotNode(nodeTxt, centerPt, parentPt, nodeType)"></a>plotNode(nodeTxt, centerPt, parentPt, nodeType)</h2><p>绘制带箭头的注解<br>annotate是关于一个数据点的文本<br>nodeTxt为要显示的文本，centerPt为文本的中心点，箭头所在的点，parentPt为指向文本的点<br>annotate的作用是添加注释，nodetxt是注释的内容<br>nodetype指的是输入的节点（边框）的形状</p><pre><code>def plotNode(nodeTxt, centerPt, parentPt, nodeType):    createPlot.ax1.annotate(nodeTxt, xy=parentPt,  xycoords=&apos;axes fraction&apos;,             xytext=centerPt, textcoords=&apos;axes fraction&apos;,             va=&quot;center&quot;, ha=&quot;center&quot;, bbox=nodeType, arrowprops=arrow_args )</code></pre><h2 id="def-createPlot"><a href="#def-createPlot" class="headerlink" title="def createPlot():"></a>def createPlot():</h2><p>第一版构造树函数，后面会改进，所以这里要注释上</p><pre><code>#fig = plt.figure(1, facecolor=&apos;white&apos;)#fig.clf()#createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses#plotNode(&apos;a decision node&apos;, (0.5, 0.1), (0.1, 0.5), decisionNode)#plotNode(&apos;a leaf node&apos;, (0.8, 0.1), (0.3, 0.8), leafNode)#plt.show()</code></pre><h2 id="getNumLeafs-myTree"><a href="#getNumLeafs-myTree" class="headerlink" title="getNumLeafs(myTree)"></a>getNumLeafs(myTree)</h2><p>计算叶子节点的个数<br>构造注解树，需要知道叶节点的个数，以便可以正确确定x轴的长度；要知道树的层数，可以确定y轴的高度。</p><pre><code>def getNumLeafs(myTree):        numLeafs = 0    firstStr = list(myTree.keys())[0]  #获得myTree的第一个键值，即第一个特征，分割的标签    #print(firstStr)    secondDict = myTree[firstStr]   #根据键值得到对应的值，即根据第一个特征分类的结果    #print(secondDict)    for key in secondDict.keys():   #获取第二个小字典中的key        if type(secondDict[key]).__name__==&apos;dict&apos;:            #判断是否小字典中是否还包含新的字典（即新的分支）            numLeafs += getNumLeafs(secondDict[key])    #包含的话进行递归从而继续循环获得新的分支所包含的叶节点的数量        else:   numLeafs +=1    #不包含的话就停止迭代并把现在的小字典加一表示这边有一个分支    return numLeafsdef getTreeDepth(myTree):   #计算判断节点的个数    maxDepth = 0    firstStr = list(myTree.keys())[0]    secondDict = myTree[firstStr]    for key in secondDict.keys():        if type(secondDict[key]).__name__==&apos;dict&apos;:            thisDepth = 1 + getTreeDepth(secondDict[key])        else:   thisDepth = 1        if thisDepth &gt; maxDepth: maxDepth = thisDepth    return maxDepth</code></pre><h2 id="retrieveTree-i"><a href="#retrieveTree-i" class="headerlink" title="retrieveTree(i)"></a>retrieveTree(i)</h2><p>预先存储树信息</p><pre><code>def retrieveTree(i):    listOfTrees =[{&apos;no surfacing&apos;: {0: &apos;no&apos;, 1: {&apos;flippers&apos;: {0: &apos;no&apos;, 1: &apos;yes&apos;}}}},                  {&apos;no surfacing&apos;: {0: &apos;no&apos;, 1: {&apos;flippers&apos;: {0: {&apos;head&apos;: {0: &apos;no&apos;, 1: &apos;yes&apos;}}, 1: &apos;no&apos;}}}}              ]    return listOfTrees[i]</code></pre><h2 id="plotMidText-cntrPt-parentPt-txtString"><a href="#plotMidText-cntrPt-parentPt-txtString" class="headerlink" title="plotMidText(cntrPt, parentPt, txtString)"></a>plotMidText(cntrPt, parentPt, txtString)</h2><p>作用是计算tree的中间位置，cntrPt起始位置,parentPt终止位置,txtString文本标签信息</p><pre><code>def plotMidText(cntrPt, parentPt, txtString):    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]  #cntrPt起点坐标，子节点坐标，parentPt结束坐标，父节点坐标    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]  #找到x和y的中间位置    createPlot.ax1.text(xMid, yMid, txtString, va=&quot;center&quot;, ha=&quot;center&quot;, rotation=30)def plotTree(myTree, parentPt, nodeTxt):    numLeafs = getNumLeafs(myTree)    depth = getTreeDepth(myTree)    firstStr = list(myTree.keys())[0]    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)   #计算子节点的坐标    plotMidText(cntrPt, parentPt, nodeTxt)      #绘制线上的文字    plotNode(firstStr, cntrPt, parentPt, decisionNode)      #绘制节点    secondDict = myTree[firstStr]    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD     #每绘制一次图，将y的坐标减少1.0/plottree.totald，间接保证y坐标上深度的    for key in secondDict.keys():        if type(secondDict[key]).__name__==&apos;dict&apos;:            plotTree(secondDict[key],cntrPt,str(key))        else:            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD</code></pre><h2 id="createPlot-inTree"><a href="#createPlot-inTree" class="headerlink" title="createPlot(inTree)"></a>createPlot(inTree)</h2><pre><code>def createPlot(inTree):    fig = plt.figure(1, facecolor=&apos;white&apos;)  #类似于Matlab的figure，定义一个画布，背景为白色    fig.clf()   # 把画布清空    axprops = dict(xticks=[], yticks=[])    #subplot定义了一个绘图    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)    #no ticks    #createPlot.ax1为全局变量，绘制图像的句柄，111表示figure中的图有1行1列，即1个，最后的1代表第一个图,frameon表示是否绘制坐标轴矩形    plotTree.totalW = float(getNumLeafs(inTree))    plotTree.totalD = float(getTreeDepth(inTree))    plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0;    plotTree(inTree, (0.5,1.0), &apos;&apos;)    plt.show()</code></pre><h1 id="treePlotter-main-py"><a href="#treePlotter-main-py" class="headerlink" title="treePlotter_main.py"></a>treePlotter_main.py</h1><pre><code>import  treePlotter#treePlotter.createPlot()#print(treePlotter.retrieveTree(1))myTree=treePlotter.retrieveTree(0)#print(treePlotter.getNumLeafs(myTree))#print(treePlotter.getTreeDepth(myTree))myTree[&apos;no surfacing&apos;][3]=&apos;maybe&apos;treePlotter.createPlot(myTree)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;p&gt;优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特诊数据&lt;br&gt;缺点：可能会产生过度匹配问题&lt;br&gt;使用数据类型：数值型和标称型&lt;br&gt;专家系统中，经常使用决策树&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://moyingyao.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习实战" scheme="http://moyingyao.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战--KNN</title>
    <link href="http://moyingyao.github.io/2018/05/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-KNN/"/>
    <id>http://moyingyao.github.io/2018/05/23/机器学习实战-KNN/</id>
    <published>2018-05-23T12:24:18.000Z</published>
    <updated>2018-05-25T03:09:14.904Z</updated>
    
    <content type="html"><![CDATA[<p>这本书的好就不多说的，其实如果不是因为机器学习那门学位课的作业是这个，我想我会错过这本书0.0</p><h1 id="knn"><a href="#knn" class="headerlink" title="knn"></a>knn</h1><p>优       点：精度高，对异常值不敏感，无数据输入假定<br>缺       点：计算复杂度高，空间复杂度高，无法给出数据的内在含义<br>使用数据范围：数值型和标称型<br><a id="more"></a><br><img src="https://i.imgur.com/1diiQIB.png" alt=""></p><p>—————————————————————–下面进入正题—————————————————————–</p><h1 id="kNN-py"><a href="#kNN-py" class="headerlink" title="kNN.py"></a>kNN.py</h1><pre><code>from numpy import *  import operator  from os import listdir  </code></pre><h2 id="def-createDataSet"><a href="#def-createDataSet" class="headerlink" title="def createDataSet()"></a>def createDataSet()</h2><pre><code>def createDataSet():      group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])      labels = [&apos;A&apos;,&apos;A&apos;,&apos;B&apos;,&apos;B&apos;]      return group, labels </code></pre><h2 id="classify0"><a href="#classify0" class="headerlink" title="classify0()"></a>classify0()</h2><p>inX用于分类的输入向量,是一个向量<br>dataSet输入的训练样本集，是一个矩阵<br>labels标签向量<br>k用于选择最近邻居的数目<br>labels数目与dataSet的行数相同 </p><pre><code>def classify0(inX, dataSet, labels, k):    dataSetSize = dataSet.shape[0]  #返回的是dataSet的行数，行数就是样本的数量    diffMat = tile(inX, (dataSetSize,1)) - dataSet  #矩阵相减    #inX是个向量，而dataset是个矩阵，两者之间要进行相减的运算，需要把这个向量也补成一个和dataset有相同行数列数的矩阵，    #tile()的第二个参数，就是(datasetsize,1)，这个参数的意思就是把inX补成有datasetsize行数的矩阵。    #假如inX是（1，2），datasetsize =3，那么经过tile()转换后产生了一个这样的矩阵（[1,2],[1,2],[1,2]）    sqDiffMat = diffMat**2  #平方    sqDistances = sqDiffMat.sum(axis=1) #按行求和    # sqdiffMat是([1,2],[0,1],[3,4])，axis这个参数影响了对矩阵求和时候的顺序，axis=0是按照列求和，结果为([3.1.7])    # axis=1是按照行进行求和，结果是([4,7])。    distances = sqDistances**0.5    #开方，得到欧氏距离    sortedDistIndicies = distances.argsort()     #把向量中每个元素进行排序，结果是元素的索引形成的向量    #例子distance([1,4,3])，经过distance.argsort()之后的结果是([0,2,1]    classCount={}       #存放最终的分类结果及相应的结果投票数    #投票过程，就是统计前k个最近的样本所属类别包含的样本个数    for i in range(k):        # index = sortedDistIndicies[i]是第i个最相近的元素索引，即样本下标        # voteIlabel = labels[index]是样本index对应的分类结果(&apos;A&apos; or &apos;B&apos;)        voteIlabel = labels[sortedDistIndicies[i]]        # classCount.get(voteIlabel, 0)返回voteIlabel的值，如果不存在，则返回0        # 然后将票数增1        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1    # 把分类结果进行排序，然后返回得票数最多的分类结果    # key=operator.itemgetter(1)的意思是按照字典里的第一个排序    #例子a = [1, 2, 3]，b = operator.itemgetter(1)，b(a)返回为2    #b = operator.itemgetter(1, 0)，b(a)，定义函数b，获取对象的第1个域和第0个的值，返回 (2, 1)    # reverse=True是降序排序    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)    return sortedClassCount[0][0] #返回类别最多的类别</code></pre><h2 id="file2matrix"><a href="#file2matrix" class="headerlink" title="file2matrix()"></a>file2matrix()</h2><p>将文本记录转换为NumPy<br>将文本记录转换为NumPy的解析程序<br>输入为矩阵，输出为训练样本矩阵和类标签向量</p><pre><code>def file2matrix(filename):    fr = open(filename)     #打开文档    numberOfLines = len(fr.readlines())        #得到文件行数    #fr.readlines()读取行数,存在数组中,导入后每行中用\t隔开,两行之间用\n换行得到文件行数    returnMat = zeros((numberOfLines,3))        #创建返回NumPy矩阵，numberoflines行，3列的初始化零的矩阵    classLabelVector = []#定义一个空的数组    fr = open(filename)    index = 0    for line in fr.readlines():        line = line.strip() #删除（）中的内容，这里表示删除空格        listFromLine = line.split(&apos;\t&apos;)#以\t分割        #print(listFromLine)        returnMat[index,:] = listFromLine[0:3]#把每行前三个元素存入returnMat矩阵中，每行中存储三个        classLabelVector.append(int(listFromLine[-1]))#存储第四列元素即标签，在数组中append添加，-1表示最后一列        index += 1    return returnMat,classLabelVector</code></pre><h2 id="autoNorm"><a href="#autoNorm" class="headerlink" title="autoNorm()"></a>autoNorm()</h2><p>归一化数值，避免某特征值过大，使得权重比例不均匀，对计算结果产生影响。<br>autoNorm可以自动将数字特征值转化为0到1区间</p><pre><code>def autoNorm(dataSet):    minVals = dataSet.min(0)#一维数组，值为各项特征（列）中的最小值。参数0使得函数从列中选取最小值    #print(minVals)    maxVals = dataSet.max(0)    #print(maxVals)    ranges = maxVals - minVals    normDataSet = zeros(shape(dataSet)) #创建与样本集一样大小的零矩阵    #print(normDataSet)    m = dataSet.shape[0]#dataSet的行数    normDataSet = dataSet - tile(minVals, (m,1))#矩阵中所有的值减去最小值    #tile将原来的一个数组minVals，扩充成了m行1列的数组    normDataSet = normDataSet/tile(ranges, (m,1))   #矩阵中所有的值除以最大取值范围进行归一化    return normDataSet, ranges, minVals</code></pre><h2 id="datingClassTest"><a href="#datingClassTest" class="headerlink" title="datingClassTest()"></a>datingClassTest()</h2><p>测试算法，样本集中百分之九十的数据用来训练样本，百分之十的样本用来测试分类器kNN.classify0()。</p><pre><code>def datingClassTest():    hoRatio = 0.10      #百分之十的数据用于测试分类器，更改该变量的值可更改参加测试分类器的数据量    datingDataMat,datingLabels = file2matrix(&apos;datingTestSet2.txt&apos;)       #导入数据    normMat, ranges, minVals = autoNorm(datingDataMat)      #归一化数值    m = normMat.shape[0]    #得到总行数    numTestVecs = int(m*hoRatio)    #测试总数据数量，m*hoRatio是一个浮点型，需转化成整形    errorCount = 0.0    #初试错误率为0    for i in range(numTestVecs):        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)        #分类器（需要测试的向量，训练样本集(90%)，标签集合，K）        print(&quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, datingLabels[i]))        if (classifierResult != datingLabels[i]): errorCount += 1.0     #计数，错误的个数    print(&quot;the total error rate is: %f&quot; % (errorCount/float(numTestVecs)))      #错误率    print(errorCount)</code></pre><h2 id="classifyPerson"><a href="#classifyPerson" class="headerlink" title="classifyPerson()"></a>classifyPerson()</h2><p>约会数据,对于未来的约会预测函数，输入飞行里程数，玩视频游戏的百分比和冰激凌公升数，可以得到一个是否对他感兴趣的预测，</p><pre><code>def classifyPerson():    resultList=[&apos;not at all&apos;,&apos;in samll doses&apos;,&apos;in large doses&apos;] #三种感兴趣程度    percentTats=float(input(&quot;percentage of time spent playing video games?&quot;))    ffMiles=floats=float(input(&quot;frequent flier miles earned per year?&quot;))    iceCream=float(input(&quot;liters of ice cream consuned per year?&quot;))#input键盘输入    datingDataMat,datingLabels=file2matrix(&apos;datingTestSet2.txt&apos;) # 导入数据    normMat,ranges,minvals=autoNorm(datingDataMat) # 归一化，ranges是归一化的分母    inArr=array([ffMiles,percentTats,iceCream]) # inArr是归一化之前的datingDataMat数组中的行    classifierResult=classify0((inArr-minvals)/ranges,normMat,datingLabels,3)#先归一化，然后调用分类函数    #print(classifierResult)    print(&quot;you will probably like this person:%s&quot;%resultList[classifierResult-1])</code></pre><h2 id="img2vector"><a href="#img2vector" class="headerlink" title="img2vector()"></a>img2vector()</h2><p>图片转向量<br>手写体：32<em>32的黑白图像<br>图片转向量，将32</em>32的二进制图像矩阵转换为1*1024的向量</p><pre><code>def img2vector(filename):    returnVect = zeros((1,1024))    fr = open(filename)    for i in range(32):#循环读出文件的前32行        lineStr = fr.readline()        for j in range(32):#将每行的前32个字符存储在NumPy数组中            returnVect[0,32*i+j] = int(lineStr[j])    return returnVect#返回数组</code></pre><h2 id="handwritingClassTest"><a href="#handwritingClassTest" class="headerlink" title="handwritingClassTest()"></a>handwritingClassTest()</h2><p>手写体测试</p><pre><code>def handwritingClassTest():    hwLabels = []    trainingFileList = listdir(&apos;trainingDigits&apos;)           #导入训练数据    #print(trainingFileList)    m = len(trainingFileList)   #训练数据的总数    #print(m)    trainingMat = zeros((m,1024))   #m行1024列的零向量    for i in range(m):        fileNameStr = trainingFileList[i]   #文件名        fileStr = fileNameStr.split(&apos;.&apos;)[0]     #取文件名.之前的名字        classNumStr = int(fileStr.split(&apos;_&apos;)[0])    #取文件名_之前的名字        hwLabels.append(classNumStr)        trainingMat[i,:] = img2vector(&apos;trainingDigits/%s&apos; % fileNameStr)    #将对应数据集下的文件一个个的转为向量        #print(trainingMat[i,:])    testFileList = listdir(&apos;testDigits&apos;)        #测试数据    errorCount = 0.0    mTest = len(testFileList)    for i in range(mTest):        fileNameStr = testFileList[i]        fileStr = fileNameStr.split(&apos;.&apos;)[0]        classNumStr = int(fileStr.split(&apos;_&apos;)[0])        vectorUnderTest = img2vector(&apos;testDigits/%s&apos; % fileNameStr)        classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3) #利用训练的trainingMat测试        print(&quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, classNumStr))        if (classifierResult != classNumStr): errorCount += 1.0    print(&quot;\nthe total number of errors is: %d&quot; % errorCount)    print(&quot;\nthe total error rate is: %f&quot; % (errorCount/float(mTest)))</code></pre><h1 id="knn-main-py"><a href="#knn-main-py" class="headerlink" title="knn_main.py"></a>knn_main.py</h1><pre><code>import kNN  import matplotlib  import matplotlib.pyplot as plt  import numpy as np  from imp import reload  group,labels=kNN.createDataSet()  #print(group)  #print(labels)  #print(kNN.classify0([0,0],group,labels,3))  </code></pre><h2 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h2><pre><code>fig=plt.figure()                #建立画板  ax=fig.add_subplot(111)         #添加一个子图，一行一列第一个子块，若括号内为349，则三行四列第9个子块  reload(kNN)  datingDataMat,datingLabels=kNN.file2matrix(&apos;datingTestSet2.txt&apos;)  #print(datingDataMat)  #ax.scatter(datingDataMat[:,1],datingDataMat[:,2])        # scatter绘制散点图,使用第二列第三列数据  #ax.scatter(datingDataMat[:,1],datingDataMat[:,2],15.0*np.array(datingLabels),15.0*np.array(datingLabels))  ax.scatter(datingDataMat[:,0],datingDataMat[:,1],15.0*np.array(datingLabels),15.0*np.array(datingLabels))  #plt.show()  </code></pre><h2 id="归一化数值"><a href="#归一化数值" class="headerlink" title="归一化数值"></a>归一化数值</h2><pre><code>normMat,ranges,minVals=kNN.autoNorm(datingDataMat)  #print(normMat)  #print(ranges)  #print(minVals)  </code></pre><h2 id="测试算法"><a href="#测试算法" class="headerlink" title="测试算法"></a>测试算法</h2><pre><code>#kNN.datingClassTest()  </code></pre><h2 id="约会预测"><a href="#约会预测" class="headerlink" title="约会预测"></a>约会预测</h2><pre><code>#对于未来的约会预测函数，输入飞行里程数，玩视频游戏的百分比和冰激凌公升数，可以得到一个是否对他感兴趣的预测，  #输入10   10000   0.5  #kNN.classifyPerson()  </code></pre><h2 id="手写体"><a href="#手写体" class="headerlink" title="手写体"></a>手写体</h2><pre><code>#trainingDigits包含大约2000个例子，每个数字约有200个样本  #testDigits包含大约900个测试数据  testVector=kNN.img2vector(&apos;trainingDigits/0_13.txt&apos;)  #print(testVector[0,0:31])  #print(testVector[0,32:63])  #print(testVector[0,64:95])  kNN.handwritingClassTest()  </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这本书的好就不多说的，其实如果不是因为机器学习那门学位课的作业是这个，我想我会错过这本书0.0&lt;/p&gt;
&lt;h1 id=&quot;knn&quot;&gt;&lt;a href=&quot;#knn&quot; class=&quot;headerlink&quot; title=&quot;knn&quot;&gt;&lt;/a&gt;knn&lt;/h1&gt;&lt;p&gt;优       点：精度高，对异常值不敏感，无数据输入假定&lt;br&gt;缺       点：计算复杂度高，空间复杂度高，无法给出数据的内在含义&lt;br&gt;使用数据范围：数值型和标称型&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://moyingyao.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习实战" scheme="http://moyingyao.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>伊始</title>
    <link href="http://moyingyao.github.io/2018/05/17/%E4%BC%8A%E5%A7%8B/"/>
    <id>http://moyingyao.github.io/2018/05/17/伊始/</id>
    <published>2018-05-17T14:27:24.000Z</published>
    <updated>2019-03-13T12:43:57.904Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to AmberWu’s Blog! 为什么会想弄这么一个博客呢，还不是因为有那么一个研究僧程序猿且男屌丝，哦不不不，大神，嗯，大神0.0。第一次接触建站域名，随便弄弄。还挺有意思的，本以为这个很难，离自己很远，动起手来，真的蛮简单的，毕竟，本学渣弄得下来，哈哈哈<br><a id="more"></a></p><h2 id="简单随便说说建站方法"><a href="#简单随便说说建站方法" class="headerlink" title="简单随便说说建站方法"></a>简单随便说说建站方法</h2><h3 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h3><p>就是以Hexo为主，剩下的自行百度吧，毕竟我要回寝室，没时间写了</p><h3 id="Github-Pages"><a href="#Github-Pages" class="headerlink" title="Github Pages"></a>Github Pages</h3><p>以github为载体实现的，也百度吧，啊啊啊，实验室就剩我自己了。</p><h3 id="配置域名"><a href="#配置域名" class="headerlink" title="配置域名"></a>配置域名</h3><p>在博客的根目录下source文件中(例如：C:\hexo\source)新建一个名为CNAME的文件，注意没有任何后缀，用于github进行读取。<br>在文件中添加自己的域名并保存，例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">amberwu.top</span><br></pre></td></tr></table></figure></p><p>然后，重新生成静态文件并部署。CNAME文件也会被上传到github仓库当中，此时在浏览器中输入自己的域名，回车之后，你会第一次遇见自己的小天地~</p><h3 id="Hexo的一些基本命令"><a href="#Hexo的一些基本命令" class="headerlink" title="Hexo的一些基本命令"></a>Hexo的一些基本命令</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g <span class="comment">#完整命令为hexo generate,用于生成静态文件</span></span><br><span class="line">hexo s <span class="comment">#完整命令为hexo server,用于启动服务器，主要用来本地预览</span></span><br></pre></td></tr></table></figure><p>在浏览器地址栏输入<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a>, 按下回车键，熟悉的界面又出现了。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo d <span class="comment">#完整命令为hexo deploy,用于将本地文件发布到github等git仓库上</span></span><br><span class="line">hexo n <span class="string">"my article"</span> <span class="comment">#完整命令为hexo new,用于新建一篇名为“my article”的文章</span></span><br></pre></td></tr></table></figure></p><p>这样就会在博客目录下source_posts中生成相应的 my article.md文件( 例如 C:\blog\source_posts\my article.md )</p><h3 id="Hexo修改及配置主题"><a href="#Hexo修改及配置主题" class="headerlink" title="Hexo修改及配置主题"></a>Hexo修改及配置主题</h3><p>hexo初始化之后默认的主题是landscape , 然后你可以去这个地址 <a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a> 里面找到你想要的主题。在github中搜索你要的主题名称，里面都会有该主题的如何使用的介绍，按着来就好了，反正就是改改改！我选的是next,看起来挺不错，至少是我喜欢的类型。<br><strong>更改主题需要修改配置文件</strong><br>更改主题需要修改配置文件，就是根目录下的_config.yml文件，找到 theme 字段，并将其值更改为next即可<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: next</span><br></pre></td></tr></table></figure></p><p><strong>配置next主题</strong><br>next主题共分三种，在站点根目录/themes/next/_congig.yml 文件中修改，找到scheme关键字即可选择。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Schemes</span></span><br><span class="line"><span class="comment">#scheme: Muse</span></span><br><span class="line"><span class="comment">#scheme: Mist</span></span><br><span class="line">scheme: Pisces</span><br></pre></td></tr></table></figure></p><p>当然，你完全可以进行很多的自定义设置甚至修改源码，定制自己的主题。小女子能力有限，更多的设置请参考官方文档<a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="noopener">http://theme-next.iissnan.com/getting-started.html</a><br><strong>添加背景图片</strong><br>将背景图片命名为background.jpg并放入主题根目录/source/images文件夹中<br>打开博客根目录/themes/next/source/css/_custom/custom.styl文件<br>加入如下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Custom styles.</span><br><span class="line">body &#123; </span><br><span class="line">background-image: url(/images/background.jpg);</span><br><span class="line">background-attachment: fixed;</span><br><span class="line">background-repeat: no-repeat;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="更多资料"><a href="#更多资料" class="headerlink" title="更多资料"></a>更多资料</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to AmberWu’s Blog! 为什么会想弄这么一个博客呢，还不是因为有那么一个研究僧程序猿且男屌丝，哦不不不，大神，嗯，大神0.0。第一次接触建站域名，随便弄弄。还挺有意思的，本以为这个很难，离自己很远，动起手来，真的蛮简单的，毕竟，本学渣弄得下来，哈哈哈&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="随便写写" scheme="http://moyingyao.github.io/categories/%E9%9A%8F%E4%BE%BF%E5%86%99%E5%86%99/"/>
    
    
      <category term="个人随笔" scheme="http://moyingyao.github.io/tags/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
